{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytextable\n",
      "  Using cached pytextable-0.2.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Using cached pytextable-0.2.1-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: pytextable\n",
      "Successfully installed pytextable-0.2.1\n"
     ]
    }
   ],
   "source": [
    "! pip install pytextable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pytextable as pytex\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hope\n",
      "3.0    11\n",
      "1.0    10\n",
      "4.0     3\n",
      "2.0     1\n",
      "Name: count, dtype: int64\n",
      "Hale\n",
      "3.0    11\n",
      "1.0     9\n",
      "4.0     4\n",
      "2.0     1\n",
      "Name: count, dtype: int64\n",
      "We agreed on 10 in half_neural_chiasm.xlsx\n",
      "Hope\n",
      "3    11\n",
      "1    11\n",
      "4     2\n",
      "2     1\n",
      "Name: count, dtype: int64\n",
      "Hale\n",
      "1    10\n",
      "3     9\n",
      "4     5\n",
      "2     1\n",
      "Name: count, dtype: int64\n",
      "We agreed on 21 in verse_neural_chiasm.xlsx\n",
      "50 50\n",
      "[0.81, 0.42]\n"
     ]
    }
   ],
   "source": [
    "# so we want a table of inter-annotator agreement score for each manuscript,\n",
    "# the human accuracy (as determined by both Hope and Hale agreeing that it's a chiasm)\n",
    "# the percentage of true chiasms in the BCE (y1==y2 & ['bce'] ==1), as marked by Hale\n",
    "import os\n",
    "table_data =[]\n",
    "dir = '../new_scripts/annotated_subsets'\n",
    "y1 = []\n",
    "y2 = []\n",
    "correct = 0\n",
    "for file in os.listdir('../new_scripts/annotated_subsets'):\n",
    "    if 'neural' in file:\n",
    "        df = pd.read_excel(os.path.join(dir, file))\n",
    "        print(df['Hope'].value_counts())\n",
    "        print(df['Hale'].value_counts())\n",
    "        df['Hope'].apply(lambda x: 1 if x==2 else x)\n",
    "        df['Hale'].apply(lambda x: 1 if x==2 else x)\n",
    "    #     df = df.dropna()\n",
    "    #     # print(df.head())\n",
    "        y1.extend(df['Hope'][:25])\n",
    "        y2.extend(df['Hale'][:25])\n",
    "        for i, row in df.iterrows():\n",
    "            if row['Hope'] == 1 or row['Hale'] == 1:\n",
    "                correct += 1\n",
    "        # consensus = df[(df['Hope'] == 1) & (df['Hale']==1)]\n",
    "        # agreed += len(consensus)\n",
    "        print(f\"We agreed on {correct} in {file}\")\n",
    "\n",
    "system_accuracy = np.round(correct/len(y1), 2)\n",
    "\n",
    "# table_data.append([manuscript, cohen_kappa, system_accuracy, true_chiasms_not_in_bce])\n",
    "\n",
    "\n",
    "print(len(y1), len(y2))\n",
    "# print(len(y1), len(y2))\n",
    "# print(y1, y2)\n",
    "cohen_kappa = np.round(cohen_kappa_score(y1, y2), 2)\n",
    "\n",
    "print([cohen_kappa, system_accuracy])\n",
    "table_data= np.asarray(table_data)\n",
    "# table_data = table_data.T\n",
    "# pytex.write(table_data, 'annotation.tex', header=['Manuscript', 'Cohen\\'s $\\kappa$', 'System Accuracy', 'New Chiasms'])\n",
    "    # this is good, it meand 20% of true chiasms aren't in BCE, so it's useful to have a system that can find them\n",
    "\n",
    "# drop rows where 'Hope' column is NaN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['old_Sinaiticus-Greek', 0.84, 0.46, 0.18]\n",
      "['new_Sinaiticus-Greek', 0.31, 0.4, 0.08]\n",
      "['old_WLC-Hebrew', 0.9, 0.71, 0.2]\n"
     ]
    }
   ],
   "source": [
    "# so we want a table of inter-annotator agreement score for each manuscript,\n",
    "# the human accuracy (as determined by both Hope and Hale agreeing that it's a chiasm)\n",
    "# the percentage of true chiasms in the BCE (y1==y2 & ['bce'] ==1), as marked by Hale\n",
    "\n",
    "table_data =[]\n",
    "for manuscript in ['old_Sinaiticus-Greek', 'new_Sinaiticus-Greek', 'old_WLC-Hebrew']:\n",
    "    df = pd.read_csv(f\"../annotated/Full_Annotated_top_scoring_{manuscript}_new-alg.csv\")\n",
    "    df = df.dropna()\n",
    "    # print(df.head())\n",
    "    y1 = df['Hope']\n",
    "    y2 = df['Hale']\n",
    "    cohen_kappa = np.round(cohen_kappa_score(y1, y2), 2)\n",
    "    # where 'Hope' and 'Hale' are both one, want sum\n",
    "    consensus = df[(df['Hope'] == 1) & (df['Hale']==1)]\n",
    "    system_accuracy = np.round(len(consensus)/len(df), 2)\n",
    "    # what percentage of true chiasms are NOT in 'bce' aka 'bce' == 0?\n",
    "    true_chiasms_not_in_bce = np.round(len(df[(df['Hope'] == 1) & (df['Hale']==1) & (df['BCE'] == 0) ])/len(df), 2)\n",
    "\n",
    "    # true_chiasms = sum((y1 == y2) & (df['BCE'] == 1)) / len(df)\n",
    "    table_data.append([manuscript, cohen_kappa, system_accuracy, true_chiasms_not_in_bce])\n",
    "    print([manuscript, cohen_kappa, system_accuracy, true_chiasms_not_in_bce])\n",
    "\n",
    "table_data= np.asarray(table_data)\n",
    "# table_data = table_data.T\n",
    "pytex.write(table_data, 'annotation.tex', header=['Manuscript', 'Cohen\\'s $\\kappa$', 'System Accuracy', 'New Chiasms'])\n",
    "    # this is good, it meand 20% of true chiasms aren't in BCE, so it's useful to have a system that can find them\n",
    "\n",
    "# drop rows where 'Hope' column is NaN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
