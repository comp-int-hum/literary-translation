{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 8489k  100 8489k    0     0  3469k      0  0:00:02  0:00:02 --:--:-- 3469k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 11.4M  100 11.4M    0     0  5488k      0  0:00:02  0:00:02 --:--:-- 5489k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 4181k  100 4181k    0     0  6475k      0 --:--:-- --:--:-- --:--:-- 6473k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 8435k  100 8435k    0     0  7655k      0  0:00:01  0:00:01 --:--:-- 7661k\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "curl -L https://raw.githubusercontent.com/STEPBible/STEPBible-Data/master/Older%20Formats/TOTHT%20Gen-Deu%20-%20Translators%20OT%20Hebrew%20Tagged%20text%20-%20STEPBible.org%20CC%20BY.txt >> ../data/STEP/Gen_Deu.txt\n",
    "curl -L https://raw.githubusercontent.com/STEPBible/STEPBible-Data/master/Older%20Formats/TOTHT%20Jos-Est%20-%20Translators%20OT%20Hebrew%20Tagged%20text%20-%20STEPBible.org%20CC%20BY.txt >> ../data/STEP/Jos_Est.txt\n",
    "curl -L https://raw.githubusercontent.com/STEPBible/STEPBible-Data/master/Older%20Formats/TOTHT%20Job-Sng%20-%20Translators%20OT%20Hebrew%20Tagged%20text%20-%20STEPBible.org%20CC%20BY.txt >> ../data/STEP/Job_Sng.txt\n",
    "curl -L https://raw.githubusercontent.com/STEPBible/STEPBible-Data/master/Older%20Formats/TOTHT%20Isa-Mal%20-%20Translators%20OT%20Hebrew%20Tagged%20text%20-%20STEPBible.org%20CC%20BY.txt >> ../data/STEP/Isa_Mal.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = '../data/STEP/'\n",
    "paths = ['Gen_Deu.txt', 'Jos_Est.txt', 'Job_Sng.txt', 'Isa_Mal.txt']\n",
    "paths = [prefix + p for p in paths]\n",
    "import json\n",
    "ATNACH = '\\u0591'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse the input data and produce the desired output\n",
    "def get_half_lines(line):\n",
    "    words = line.split()\n",
    "    split = None\n",
    "    for i, w in enumerate(words):\n",
    "        if ATNACH in w:\n",
    "            split = i\n",
    "    if split != None:\n",
    "        return ' '.join(words[:split+1]), ' '.join(words[split+1:])\n",
    "    else:\n",
    "        return line, ''\n",
    "\n",
    "\n",
    "def parse_data_file(input_file, keep_sep=False, priority='Hebrew'):\n",
    "    parsed_data = []\n",
    "    current_ref = None\n",
    "    current_text = []\n",
    "    # Open the input file for reading\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "        # Iterate through each line in the file, skipping headers\n",
    "        for line in lines[45:]:\n",
    "            columns = line.strip().split('\\t')\n",
    "            if len(columns) < 6:\n",
    "                continue  # Skip lines that do not have enough data\n",
    "\n",
    "            heb_ref, eng_ref, pointed, accented, morphology, extended_strongs = columns\n",
    "\n",
    "            # Extract the Hebrew and English references, ignoring the word number\n",
    "            heb_verse = heb_ref.split('-')[0]\n",
    "            eng_verse = eng_ref.split('-')[0]\n",
    "\n",
    "            if not keep_sep:\n",
    "                accented = accented.replace('/', '')\n",
    "            else:\n",
    "                accented = accented.replace('/', ' ')\n",
    "\n",
    "            # # If we're still processing the same reference, keep appending words\n",
    "            # as some verses break different places, this tells us whether we want Hebrew or English verse breaks to have priority\n",
    "            if priority == \"Hebrew\":\n",
    "                comp = heb_verse\n",
    "            elif priority == \"English\":\n",
    "                comp = eng_verse\n",
    "\n",
    "            if current_ref == comp:\n",
    "                current_text.append(accented)\n",
    "            else:\n",
    "                # If we encounter a new reference, store the previous one (if it exists)\n",
    "                if current_ref is not None:\n",
    "                    line = ' '.join(current_text)\n",
    "                    half_a, half_b = get_half_lines(line)\n",
    "                    parsed_data.append({\n",
    "                        'heb_ref': current_ref,\n",
    "                        'eng_ref': current_eng_ref,\n",
    "                        'line': line,\n",
    "                        'half_a': half_a,\n",
    "                        'half_b': half_b\n",
    "                    })\n",
    "                # Start collecting data for the new reference\n",
    "                current_ref = heb_verse\n",
    "                current_eng_ref = eng_verse\n",
    "                current_text = [accented]\n",
    "\n",
    "        # Append the last collected reference\n",
    "        if current_ref:\n",
    "            line = ' '.join(current_text)\n",
    "            half_a, half_b = get_half_lines(line)\n",
    "            parsed_data.append({\n",
    "                'heb_ref': heb_verse,\n",
    "                'eng_ref': eng_verse,\n",
    "                'line': line,\n",
    "                'half_a': half_a,\n",
    "                'half_b': half_b\n",
    "            })\n",
    "    return parsed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for p in paths:\n",
    "    data.extend(parse_data_file(p, keep_sep=True, priority='Hebrew'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'heb_ref': 'Gen.1.1',\n",
       "  'eng_ref': 'Gen.1.1',\n",
       "  'line': 'בְּ רֵאשִׁ֖ית בָּרָ֣א אֱלֹהִ֑ים אֵ֥ת הַ שָּׁמַ֖יִם וְ אֵ֥ת הָ אָֽרֶץ ׃',\n",
       "  'half_a': 'בְּ רֵאשִׁ֖ית בָּרָ֣א אֱלֹהִ֑ים',\n",
       "  'half_b': 'אֵ֥ת הַ שָּׁמַ֖יִם וְ אֵ֥ת הָ אָֽרֶץ ׃'},\n",
       " {'heb_ref': 'Gen.1.2',\n",
       "  'eng_ref': 'Gen.1.2',\n",
       "  'line': 'וְ הָ אָ֗רֶץ הָיְתָ֥ה תֹ֙הוּ֙ וָ בֹ֔הוּ וְ חֹ֖שֶׁךְ עַל ־ פְּנֵ֣י תְה֑וֹם וְ ר֣וּחַ אֱלֹהִ֔ים מְרַחֶ֖פֶת עַל ־ פְּנֵ֥י הַ מָּֽיִם ׃',\n",
       "  'half_a': 'וְ הָ אָ֗רֶץ הָיְתָ֥ה תֹ֙הוּ֙ וָ בֹ֔הוּ וְ חֹ֖שֶׁךְ עַל ־ פְּנֵ֣י תְה֑וֹם',\n",
       "  'half_b': 'וְ ר֣וּחַ אֱלֹהִ֔ים מְרַחֶ֖פֶת עַל ־ פְּנֵ֥י הַ מָּֽיִם ׃'},\n",
       " {'heb_ref': 'Gen.1.3',\n",
       "  'eng_ref': 'Gen.1.3',\n",
       "  'line': 'וַ יֹּ֥אמֶר אֱלֹהִ֖ים יְהִ֣י א֑וֹר וַֽ יְהִי ־ אֽוֹר ׃',\n",
       "  'half_a': 'וַ יֹּ֥אמֶר אֱלֹהִ֖ים יְהִ֣י א֑וֹר',\n",
       "  'half_b': 'וַֽ יְהִי ־ אֽוֹר ׃'},\n",
       " {'heb_ref': 'Gen.1.4',\n",
       "  'eng_ref': 'Gen.1.4',\n",
       "  'line': 'וַ יַּ֧רְא אֱלֹהִ֛ים אֶת ־ הָ א֖וֹר כִּי ־ ט֑וֹב וַ יַּבְדֵּ֣ל אֱלֹהִ֔ים בֵּ֥ין הָ א֖וֹר וּ בֵ֥ין הַ חֹֽשֶׁךְ ׃',\n",
       "  'half_a': 'וַ יַּ֧רְא אֱלֹהִ֛ים אֶת ־ הָ א֖וֹר כִּי ־ ט֑וֹב',\n",
       "  'half_b': 'וַ יַּבְדֵּ֣ל אֱלֹהִ֔ים בֵּ֥ין הָ א֖וֹר וּ בֵ֥ין הַ חֹֽשֶׁךְ ׃'},\n",
       " {'heb_ref': 'Gen.1.5',\n",
       "  'eng_ref': 'Gen.1.5',\n",
       "  'line': 'וַ יִּקְרָ֨א אֱלֹהִ֤ים ׀ לָ אוֹר֙ י֔וֹם וְ לַ חֹ֖שֶׁךְ קָ֣רָא לָ֑יְלָה וַֽ יְהִי ־ עֶ֥רֶב וַֽ יְהִי ־ בֹ֖קֶר י֥וֹם אֶחָֽד ׃ פ',\n",
       "  'half_a': 'וַ יִּקְרָ֨א אֱלֹהִ֤ים ׀ לָ אוֹר֙ י֔וֹם וְ לַ חֹ֖שֶׁךְ קָ֣רָא לָ֑יְלָה',\n",
       "  'half_b': 'וַֽ יְהִי ־ עֶ֥רֶב וַֽ יְהִי ־ בֹ֖קֶר י֥וֹם אֶחָֽד ׃ פ'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now adding the English translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 17.3M  100 17.3M    0     0  2150k      0  0:00:08  0:00:08 --:--:-- 3263k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 23.3M  100 23.3M    0     0  3526k      0  0:00:06  0:00:06 --:--:-- 4594k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 9316k  100 9316k    0     0  3564k      0  0:00:02  0:00:02 --:--:-- 3565k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 17.1M  100 17.1M    0     0  5470k      0  0:00:03  0:00:03 --:--:-- 5469k\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "curl -L https://raw.githubusercontent.com/STEPBible/STEPBible-Data/master/Translators%20Amalgamated%20OT%2BNT/TAHOT%20Gen-Deu%20-%20Translators%20Amalgamated%20Hebrew%20OT%20-%20STEPBible.org%20CC%20BY.txt > ../data/STEP/Gen_Deu_eng.txt\n",
    "curl -L https://raw.githubusercontent.com/STEPBible/STEPBible-Data/master/Translators%20Amalgamated%20OT%2BNT/TAHOT%20Jos-Est%20-%20Translators%20Amalgamated%20Hebrew%20OT%20-%20STEPBible.org%20CC%20BY.txt > ../data/STEP/Jos_Est_eng.txt\n",
    "curl -L https://raw.githubusercontent.com/STEPBible/STEPBible-Data/master/Translators%20Amalgamated%20OT%2BNT/TAHOT%20Job-Sng%20-%20Translators%20Amalgamated%20Hebrew%20OT%20-%20STEPBible.org%20CC%20BY.txt > ../data/STEP/Job_Sng_eng.txt\n",
    "curl -L https://raw.githubusercontent.com/STEPBible/STEPBible-Data/master/Translators%20Amalgamated%20OT%2BNT/TAHOT%20Isa-Mal%20-%20Translators%20Amalgamated%20Hebrew%20OT%20-%20STEPBible.org%20CC%20BY.txt > ../data/STEP/Isa_Mal_eng.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'eng_ref': 'Gen.1.1',\n",
       "  'heb_ref': 'Gen.1.1',\n",
       "  'translation': 'in/ beginning he created God <obj.> the/ heavens and/ <obj.> the/ earth'},\n",
       " {'eng_ref': 'Gen.1.2',\n",
       "  'heb_ref': 'Gen.1.2',\n",
       "  'translation': 'and/ the/ earth <it> was formlessness and/ emptiness and/ darkness [was] over [the] surface of [the] deep and/ [the] spirit of God [was] hovering over [the] surface of the/ waters'},\n",
       " {'eng_ref': 'Gen.1.3',\n",
       "  'heb_ref': 'Gen.1.3',\n",
       "  'translation': 'and/ he said God let it be light and/ there was light'},\n",
       " {'eng_ref': 'Gen.1.4',\n",
       "  'heb_ref': 'Gen.1.4',\n",
       "  'translation': 'and/ he saw God <obj.> the/ light that [it was] good and/ he separated God between the/ light and/ between the/ darkness'},\n",
       " {'eng_ref': 'Gen.1.5',\n",
       "  'heb_ref': 'Gen.1.5',\n",
       "  'translation': 'and/ he called God <to> the/ light day and/ <to> the/ darkness he called night and/ there was evening and/ there was morning day one'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def parse_eng_data_file(file_path):\n",
    "    parsed_data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "        curr_ref = None\n",
    "        for i, line in enumerate(lines):\n",
    "            if line.startswith(\"# \"):\n",
    "                ref = line.split(\"\\t\")[0].split(\"# \")[1].strip().rstrip()\n",
    "                translation = lines[i+1].split(\"#_Translation\")[1].strip().rstrip().replace('\\t', ' ')\n",
    "                if len(ref.split()) >1:\n",
    "                    # formatted as Gen.31.55 (Heb: 32.1)\n",
    "                    eng_ref = ref.split()[0]\n",
    "                    heb_ref = eng_ref.split('.')[0] + '.'+ ref.split('Heb: ')[1].replace(')', '')\n",
    "                    #heb_ref = eng_ref.split('.')[0] + '.' + ref.split()[-1].replace('(', '').replace(\")\", '')\n",
    "                    \n",
    "                else:\n",
    "                    eng_ref = ref\n",
    "                    heb_ref = eng_ref\n",
    "                \n",
    "\n",
    "                curr_ref = eng_ref\n",
    "                parsed_data.append({'eng_ref': eng_ref,\n",
    "                                    'heb_ref': heb_ref,\n",
    "                                    'translation': translation,\n",
    "                                    })         \n",
    "            elif line.startswith(f\"#_{curr_ref}\"):\n",
    "                # if there is a subsequent line with the rest of the info\n",
    "                extra_translation  = lines[i+1].split(\"#_Translation\")[1].strip().rstrip().replace('\\t', ' ')\n",
    "                # grab the last entry in parsed_data and add in the translation\n",
    "                parsed_data[-1]['translation'] += \" \" + extra_translation  \n",
    "\n",
    "    return parsed_data\n",
    "\n",
    "eng_data = []\n",
    "prefix = '../data/STEP/'\n",
    "paths = ['Gen_Deu_eng.txt','Jos_Est_eng.txt', 'Job_Sng_eng.txt', 'Isa_Mal_eng.txt']\n",
    "for p in [prefix+pth for pth in paths]:\n",
    "    eng_data.extend(parse_eng_data_file(p))\n",
    "\n",
    "eng_data[:5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>heb_ref</th>\n",
       "      <th>eng_ref</th>\n",
       "      <th>line</th>\n",
       "      <th>half_a</th>\n",
       "      <th>half_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gen.1.1</td>\n",
       "      <td>Gen.1.1</td>\n",
       "      <td>בְּ רֵאשִׁ֖ית בָּרָ֣א אֱלֹהִ֑ים אֵ֥ת הַ שָּׁמַ...</td>\n",
       "      <td>בְּ רֵאשִׁ֖ית בָּרָ֣א אֱלֹהִ֑ים</td>\n",
       "      <td>אֵ֥ת הַ שָּׁמַ֖יִם וְ אֵ֥ת הָ אָֽרֶץ ׃</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gen.1.2</td>\n",
       "      <td>Gen.1.2</td>\n",
       "      <td>וְ הָ אָ֗רֶץ הָיְתָ֥ה תֹ֙הוּ֙ וָ בֹ֔הוּ וְ חֹ֖...</td>\n",
       "      <td>וְ הָ אָ֗רֶץ הָיְתָ֥ה תֹ֙הוּ֙ וָ בֹ֔הוּ וְ חֹ֖...</td>\n",
       "      <td>וְ ר֣וּחַ אֱלֹהִ֔ים מְרַחֶ֖פֶת עַל ־ פְּנֵ֥י ה...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gen.1.3</td>\n",
       "      <td>Gen.1.3</td>\n",
       "      <td>וַ יֹּ֥אמֶר אֱלֹהִ֖ים יְהִ֣י א֑וֹר וַֽ יְהִי ־...</td>\n",
       "      <td>וַ יֹּ֥אמֶר אֱלֹהִ֖ים יְהִ֣י א֑וֹר</td>\n",
       "      <td>וַֽ יְהִי ־ אֽוֹר ׃</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gen.1.4</td>\n",
       "      <td>Gen.1.4</td>\n",
       "      <td>וַ יַּ֧רְא אֱלֹהִ֛ים אֶת ־ הָ א֖וֹר כִּי ־ ט֑ו...</td>\n",
       "      <td>וַ יַּ֧רְא אֱלֹהִ֛ים אֶת ־ הָ א֖וֹר כִּי ־ ט֑וֹב</td>\n",
       "      <td>וַ יַּבְדֵּ֣ל אֱלֹהִ֔ים בֵּ֥ין הָ א֖וֹר וּ בֵ֥...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gen.1.5</td>\n",
       "      <td>Gen.1.5</td>\n",
       "      <td>וַ יִּקְרָ֨א אֱלֹהִ֤ים ׀ לָ אוֹר֙ י֔וֹם וְ לַ ...</td>\n",
       "      <td>וַ יִּקְרָ֨א אֱלֹהִ֤ים ׀ לָ אוֹר֙ י֔וֹם וְ לַ ...</td>\n",
       "      <td>וַֽ יְהִי ־ עֶ֥רֶב וַֽ יְהִי ־ בֹ֖קֶר י֥וֹם אֶ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   heb_ref  eng_ref                                               line  \\\n",
       "0  Gen.1.1  Gen.1.1  בְּ רֵאשִׁ֖ית בָּרָ֣א אֱלֹהִ֑ים אֵ֥ת הַ שָּׁמַ...   \n",
       "1  Gen.1.2  Gen.1.2  וְ הָ אָ֗רֶץ הָיְתָ֥ה תֹ֙הוּ֙ וָ בֹ֔הוּ וְ חֹ֖...   \n",
       "2  Gen.1.3  Gen.1.3  וַ יֹּ֥אמֶר אֱלֹהִ֖ים יְהִ֣י א֑וֹר וַֽ יְהִי ־...   \n",
       "3  Gen.1.4  Gen.1.4  וַ יַּ֧רְא אֱלֹהִ֛ים אֶת ־ הָ א֖וֹר כִּי ־ ט֑ו...   \n",
       "4  Gen.1.5  Gen.1.5  וַ יִּקְרָ֨א אֱלֹהִ֤ים ׀ לָ אוֹר֙ י֔וֹם וְ לַ ...   \n",
       "\n",
       "                                              half_a  \\\n",
       "0                    בְּ רֵאשִׁ֖ית בָּרָ֣א אֱלֹהִ֑ים   \n",
       "1  וְ הָ אָ֗רֶץ הָיְתָ֥ה תֹ֙הוּ֙ וָ בֹ֔הוּ וְ חֹ֖...   \n",
       "2                 וַ יֹּ֥אמֶר אֱלֹהִ֖ים יְהִ֣י א֑וֹר   \n",
       "3   וַ יַּ֧רְא אֱלֹהִ֛ים אֶת ־ הָ א֖וֹר כִּי ־ ט֑וֹב   \n",
       "4  וַ יִּקְרָ֨א אֱלֹהִ֤ים ׀ לָ אוֹר֙ י֔וֹם וְ לַ ...   \n",
       "\n",
       "                                              half_b  \n",
       "0             אֵ֥ת הַ שָּׁמַ֖יִם וְ אֵ֥ת הָ אָֽרֶץ ׃  \n",
       "1  וְ ר֣וּחַ אֱלֹהִ֔ים מְרַחֶ֖פֶת עַל ־ פְּנֵ֥י ה...  \n",
       "2                                וַֽ יְהִי ־ אֽוֹר ׃  \n",
       "3  וַ יַּבְדֵּ֣ל אֱלֹהִ֔ים בֵּ֥ין הָ א֖וֹר וּ בֵ֥...  \n",
       "4  וַֽ יְהִי ־ עֶ֥רֶב וַֽ יְהִי ־ בֹ֖קֶר י֥וֹם אֶ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's make it into a dataframe, merge on eng_ref, and then hopefully we have a perfectly aligned dataframe\n",
    "import pandas as pd\n",
    "\n",
    "heb = pd.DataFrame.from_records(data)\n",
    "heb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng_ref</th>\n",
       "      <th>heb_ref</th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gen.1.1</td>\n",
       "      <td>Gen.1.1</td>\n",
       "      <td>in/ beginning he created God &lt;obj.&gt; the/ heave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gen.1.2</td>\n",
       "      <td>Gen.1.2</td>\n",
       "      <td>and/ the/ earth &lt;it&gt; was formlessness and/ emp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gen.1.3</td>\n",
       "      <td>Gen.1.3</td>\n",
       "      <td>and/ he said God let it be light and/ there wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gen.1.4</td>\n",
       "      <td>Gen.1.4</td>\n",
       "      <td>and/ he saw God &lt;obj.&gt; the/ light that [it was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gen.1.5</td>\n",
       "      <td>Gen.1.5</td>\n",
       "      <td>and/ he called God &lt;to&gt; the/ light day and/ &lt;t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   eng_ref  heb_ref                                        translation\n",
       "0  Gen.1.1  Gen.1.1  in/ beginning he created God <obj.> the/ heave...\n",
       "1  Gen.1.2  Gen.1.2  and/ the/ earth <it> was formlessness and/ emp...\n",
       "2  Gen.1.3  Gen.1.3  and/ he said God let it be light and/ there wa...\n",
       "3  Gen.1.4  Gen.1.4  and/ he saw God <obj.> the/ light that [it was...\n",
       "4  Gen.1.5  Gen.1.5  and/ he called God <to> the/ light day and/ <t..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng = pd.DataFrame.from_records(eng_data)\n",
    "eng.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>heb_ref_x</th>\n",
       "      <th>eng_ref</th>\n",
       "      <th>line</th>\n",
       "      <th>half_a</th>\n",
       "      <th>half_b</th>\n",
       "      <th>heb_ref_y</th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gen.1.1</td>\n",
       "      <td>Gen.1.1</td>\n",
       "      <td>בְּ רֵאשִׁ֖ית בָּרָ֣א אֱלֹהִ֑ים אֵ֥ת הַ שָּׁמַ...</td>\n",
       "      <td>בְּ רֵאשִׁ֖ית בָּרָ֣א אֱלֹהִ֑ים</td>\n",
       "      <td>אֵ֥ת הַ שָּׁמַ֖יִם וְ אֵ֥ת הָ אָֽרֶץ ׃</td>\n",
       "      <td>Gen.1.1</td>\n",
       "      <td>in/ beginning he created God &lt;obj.&gt; the/ heave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gen.1.2</td>\n",
       "      <td>Gen.1.2</td>\n",
       "      <td>וְ הָ אָ֗רֶץ הָיְתָ֥ה תֹ֙הוּ֙ וָ בֹ֔הוּ וְ חֹ֖...</td>\n",
       "      <td>וְ הָ אָ֗רֶץ הָיְתָ֥ה תֹ֙הוּ֙ וָ בֹ֔הוּ וְ חֹ֖...</td>\n",
       "      <td>וְ ר֣וּחַ אֱלֹהִ֔ים מְרַחֶ֖פֶת עַל ־ פְּנֵ֥י ה...</td>\n",
       "      <td>Gen.1.2</td>\n",
       "      <td>and/ the/ earth &lt;it&gt; was formlessness and/ emp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gen.1.3</td>\n",
       "      <td>Gen.1.3</td>\n",
       "      <td>וַ יֹּ֥אמֶר אֱלֹהִ֖ים יְהִ֣י א֑וֹר וַֽ יְהִי ־...</td>\n",
       "      <td>וַ יֹּ֥אמֶר אֱלֹהִ֖ים יְהִ֣י א֑וֹר</td>\n",
       "      <td>וַֽ יְהִי ־ אֽוֹר ׃</td>\n",
       "      <td>Gen.1.3</td>\n",
       "      <td>and/ he said God let it be light and/ there wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gen.1.4</td>\n",
       "      <td>Gen.1.4</td>\n",
       "      <td>וַ יַּ֧רְא אֱלֹהִ֛ים אֶת ־ הָ א֖וֹר כִּי ־ ט֑ו...</td>\n",
       "      <td>וַ יַּ֧רְא אֱלֹהִ֛ים אֶת ־ הָ א֖וֹר כִּי ־ ט֑וֹב</td>\n",
       "      <td>וַ יַּבְדֵּ֣ל אֱלֹהִ֔ים בֵּ֥ין הָ א֖וֹר וּ בֵ֥...</td>\n",
       "      <td>Gen.1.4</td>\n",
       "      <td>and/ he saw God &lt;obj.&gt; the/ light that [it was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gen.1.5</td>\n",
       "      <td>Gen.1.5</td>\n",
       "      <td>וַ יִּקְרָ֨א אֱלֹהִ֤ים ׀ לָ אוֹר֙ י֔וֹם וְ לַ ...</td>\n",
       "      <td>וַ יִּקְרָ֨א אֱלֹהִ֤ים ׀ לָ אוֹר֙ י֔וֹם וְ לַ ...</td>\n",
       "      <td>וַֽ יְהִי ־ עֶ֥רֶב וַֽ יְהִי ־ בֹ֖קֶר י֥וֹם אֶ...</td>\n",
       "      <td>Gen.1.5</td>\n",
       "      <td>and/ he called God &lt;to&gt; the/ light day and/ &lt;t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  heb_ref_x  eng_ref                                               line  \\\n",
       "0   Gen.1.1  Gen.1.1  בְּ רֵאשִׁ֖ית בָּרָ֣א אֱלֹהִ֑ים אֵ֥ת הַ שָּׁמַ...   \n",
       "1   Gen.1.2  Gen.1.2  וְ הָ אָ֗רֶץ הָיְתָ֥ה תֹ֙הוּ֙ וָ בֹ֔הוּ וְ חֹ֖...   \n",
       "2   Gen.1.3  Gen.1.3  וַ יֹּ֥אמֶר אֱלֹהִ֖ים יְהִ֣י א֑וֹר וַֽ יְהִי ־...   \n",
       "3   Gen.1.4  Gen.1.4  וַ יַּ֧רְא אֱלֹהִ֛ים אֶת ־ הָ א֖וֹר כִּי ־ ט֑ו...   \n",
       "4   Gen.1.5  Gen.1.5  וַ יִּקְרָ֨א אֱלֹהִ֤ים ׀ לָ אוֹר֙ י֔וֹם וְ לַ ...   \n",
       "\n",
       "                                              half_a  \\\n",
       "0                    בְּ רֵאשִׁ֖ית בָּרָ֣א אֱלֹהִ֑ים   \n",
       "1  וְ הָ אָ֗רֶץ הָיְתָ֥ה תֹ֙הוּ֙ וָ בֹ֔הוּ וְ חֹ֖...   \n",
       "2                 וַ יֹּ֥אמֶר אֱלֹהִ֖ים יְהִ֣י א֑וֹר   \n",
       "3   וַ יַּ֧רְא אֱלֹהִ֛ים אֶת ־ הָ א֖וֹר כִּי ־ ט֑וֹב   \n",
       "4  וַ יִּקְרָ֨א אֱלֹהִ֤ים ׀ לָ אוֹר֙ י֔וֹם וְ לַ ...   \n",
       "\n",
       "                                              half_b heb_ref_y  \\\n",
       "0             אֵ֥ת הַ שָּׁמַ֖יִם וְ אֵ֥ת הָ אָֽרֶץ ׃   Gen.1.1   \n",
       "1  וְ ר֣וּחַ אֱלֹהִ֔ים מְרַחֶ֖פֶת עַל ־ פְּנֵ֥י ה...   Gen.1.2   \n",
       "2                                וַֽ יְהִי ־ אֽוֹר ׃   Gen.1.3   \n",
       "3  וַ יַּבְדֵּ֣ל אֱלֹהִ֔ים בֵּ֥ין הָ א֖וֹר וּ בֵ֥...   Gen.1.4   \n",
       "4  וַֽ יְהִי ־ עֶ֥רֶב וַֽ יְהִי ־ בֹ֖קֶר י֥וֹם אֶ...   Gen.1.5   \n",
       "\n",
       "                                         translation  \n",
       "0  in/ beginning he created God <obj.> the/ heave...  \n",
       "1  and/ the/ earth <it> was formlessness and/ emp...  \n",
       "2  and/ he said God let it be light and/ there wa...  \n",
       "3  and/ he saw God <obj.> the/ light that [it was...  \n",
       "4  and/ he called God <to> the/ light day and/ <t...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_OT = pd.merge(heb, eng, on='eng_ref')\n",
    "# this creates heb_ref_x and heb_ref_y. we want to make certain that these are the same. If so\n",
    "all_OT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>heb_ref_x</th>\n",
       "      <th>eng_ref</th>\n",
       "      <th>line</th>\n",
       "      <th>half_a</th>\n",
       "      <th>half_b</th>\n",
       "      <th>heb_ref_y</th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [heb_ref_x, eng_ref, line, half_a, half_b, heb_ref_y, translation]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_OT[all_OT['eng_ref']==None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_OT[all_OT['heb_ref_x'] != all_OT['heb_ref_y']].to_csv('non_matching.csv')\n",
    "# I see, so there are some cases the verse in English divides the verse differently. We do have exactly the words that belong to each verse in the non-Eng files, but I don't think we need it.\n",
    "# I think we should, however, keep the more detailed column that includes ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng_ref</th>\n",
       "      <th>heb_ref</th>\n",
       "      <th>line</th>\n",
       "      <th>translation</th>\n",
       "      <th>half_a</th>\n",
       "      <th>half_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gen.1.1</td>\n",
       "      <td>Gen.1.1</td>\n",
       "      <td>בְּ רֵאשִׁ֖ית בָּרָ֣א אֱלֹהִ֑ים אֵ֥ת הַ שָּׁמַ...</td>\n",
       "      <td>in/ beginning he created God &lt;obj.&gt; the/ heave...</td>\n",
       "      <td>בְּ רֵאשִׁ֖ית בָּרָ֣א אֱלֹהִ֑ים</td>\n",
       "      <td>אֵ֥ת הַ שָּׁמַ֖יִם וְ אֵ֥ת הָ אָֽרֶץ ׃</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gen.1.2</td>\n",
       "      <td>Gen.1.2</td>\n",
       "      <td>וְ הָ אָ֗רֶץ הָיְתָ֥ה תֹ֙הוּ֙ וָ בֹ֔הוּ וְ חֹ֖...</td>\n",
       "      <td>and/ the/ earth &lt;it&gt; was formlessness and/ emp...</td>\n",
       "      <td>וְ הָ אָ֗רֶץ הָיְתָ֥ה תֹ֙הוּ֙ וָ בֹ֔הוּ וְ חֹ֖...</td>\n",
       "      <td>וְ ר֣וּחַ אֱלֹהִ֔ים מְרַחֶ֖פֶת עַל ־ פְּנֵ֥י ה...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gen.1.3</td>\n",
       "      <td>Gen.1.3</td>\n",
       "      <td>וַ יֹּ֥אמֶר אֱלֹהִ֖ים יְהִ֣י א֑וֹר וַֽ יְהִי ־...</td>\n",
       "      <td>and/ he said God let it be light and/ there wa...</td>\n",
       "      <td>וַ יֹּ֥אמֶר אֱלֹהִ֖ים יְהִ֣י א֑וֹר</td>\n",
       "      <td>וַֽ יְהִי ־ אֽוֹר ׃</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gen.1.4</td>\n",
       "      <td>Gen.1.4</td>\n",
       "      <td>וַ יַּ֧רְא אֱלֹהִ֛ים אֶת ־ הָ א֖וֹר כִּי ־ ט֑ו...</td>\n",
       "      <td>and/ he saw God &lt;obj.&gt; the/ light that [it was...</td>\n",
       "      <td>וַ יַּ֧רְא אֱלֹהִ֛ים אֶת ־ הָ א֖וֹר כִּי ־ ט֑וֹב</td>\n",
       "      <td>וַ יַּבְדֵּ֣ל אֱלֹהִ֔ים בֵּ֥ין הָ א֖וֹר וּ בֵ֥...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gen.1.5</td>\n",
       "      <td>Gen.1.5</td>\n",
       "      <td>וַ יִּקְרָ֨א אֱלֹהִ֤ים ׀ לָ אוֹר֙ י֔וֹם וְ לַ ...</td>\n",
       "      <td>and/ he called God &lt;to&gt; the/ light day and/ &lt;t...</td>\n",
       "      <td>וַ יִּקְרָ֨א אֱלֹהִ֤ים ׀ לָ אוֹר֙ י֔וֹם וְ לַ ...</td>\n",
       "      <td>וַֽ יְהִי ־ עֶ֥רֶב וַֽ יְהִי ־ בֹ֖קֶר י֥וֹם אֶ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   eng_ref  heb_ref                                               line  \\\n",
       "0  Gen.1.1  Gen.1.1  בְּ רֵאשִׁ֖ית בָּרָ֣א אֱלֹהִ֑ים אֵ֥ת הַ שָּׁמַ...   \n",
       "1  Gen.1.2  Gen.1.2  וְ הָ אָ֗רֶץ הָיְתָ֥ה תֹ֙הוּ֙ וָ בֹ֔הוּ וְ חֹ֖...   \n",
       "2  Gen.1.3  Gen.1.3  וַ יֹּ֥אמֶר אֱלֹהִ֖ים יְהִ֣י א֑וֹר וַֽ יְהִי ־...   \n",
       "3  Gen.1.4  Gen.1.4  וַ יַּ֧רְא אֱלֹהִ֛ים אֶת ־ הָ א֖וֹר כִּי ־ ט֑ו...   \n",
       "4  Gen.1.5  Gen.1.5  וַ יִּקְרָ֨א אֱלֹהִ֤ים ׀ לָ אוֹר֙ י֔וֹם וְ לַ ...   \n",
       "\n",
       "                                         translation  \\\n",
       "0  in/ beginning he created God <obj.> the/ heave...   \n",
       "1  and/ the/ earth <it> was formlessness and/ emp...   \n",
       "2  and/ he said God let it be light and/ there wa...   \n",
       "3  and/ he saw God <obj.> the/ light that [it was...   \n",
       "4  and/ he called God <to> the/ light day and/ <t...   \n",
       "\n",
       "                                              half_a  \\\n",
       "0                    בְּ רֵאשִׁ֖ית בָּרָ֣א אֱלֹהִ֑ים   \n",
       "1  וְ הָ אָ֗רֶץ הָיְתָ֥ה תֹ֙הוּ֙ וָ בֹ֔הוּ וְ חֹ֖...   \n",
       "2                 וַ יֹּ֥אמֶר אֱלֹהִ֖ים יְהִ֣י א֑וֹר   \n",
       "3   וַ יַּ֧רְא אֱלֹהִ֛ים אֶת ־ הָ א֖וֹר כִּי ־ ט֑וֹב   \n",
       "4  וַ יִּקְרָ֨א אֱלֹהִ֤ים ׀ לָ אוֹר֙ י֔וֹם וְ לַ ...   \n",
       "\n",
       "                                              half_b  \n",
       "0             אֵ֥ת הַ שָּׁמַ֖יִם וְ אֵ֥ת הָ אָֽרֶץ ׃  \n",
       "1  וְ ר֣וּחַ אֱלֹהִ֔ים מְרַחֶ֖פֶת עַל ־ פְּנֵ֥י ה...  \n",
       "2                                וַֽ יְהִי ־ אֽוֹר ׃  \n",
       "3  וַ יַּבְדֵּ֣ל אֱלֹהִ֔ים בֵּ֥ין הָ א֖וֹר וּ בֵ֥...  \n",
       "4  וַֽ יְהִי ־ עֶ֥רֶב וַֽ יְהִי ־ בֹ֖קֶר י֥וֹם אֶ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_OT = all_OT.rename(columns = {'heb_ref_x': 'heb_ref'})\n",
    "all_OT = all_OT.drop(columns =['heb_ref_y'])\n",
    "all_OT= all_OT[['eng_ref', 'heb_ref', 'line', 'translation', 'half_a', 'half_b']]\n",
    "all_OT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng_ref</th>\n",
       "      <th>heb_ref</th>\n",
       "      <th>line</th>\n",
       "      <th>translation</th>\n",
       "      <th>half_a</th>\n",
       "      <th>half_b</th>\n",
       "      <th>trans_a</th>\n",
       "      <th>trans_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gen.1.1</td>\n",
       "      <td>Gen.1.1</td>\n",
       "      <td>בְּ רֵאשִׁ֖ית בָּרָ֣א אֱלֹהִ֑ים אֵ֥ת הַ שָּׁמַ...</td>\n",
       "      <td>in/ beginning he created God &lt;obj.&gt; the/ heave...</td>\n",
       "      <td>בְּ רֵאשִׁ֖ית בָּרָ֣א אֱלֹהִ֑ים</td>\n",
       "      <td>אֵ֥ת הַ שָּׁמַ֖יִם וְ אֵ֥ת הָ אָֽרֶץ ׃</td>\n",
       "      <td>in/ beginning he created God &lt;obj.&gt;</td>\n",
       "      <td>the/ heavens and/ &lt;obj.&gt; the/ earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gen.1.2</td>\n",
       "      <td>Gen.1.2</td>\n",
       "      <td>וְ הָ אָ֗רֶץ הָיְתָ֥ה תֹ֙הוּ֙ וָ בֹ֔הוּ וְ חֹ֖...</td>\n",
       "      <td>and/ the/ earth &lt;it&gt; was formlessness and/ emp...</td>\n",
       "      <td>וְ הָ אָ֗רֶץ הָיְתָ֥ה תֹ֙הוּ֙ וָ בֹ֔הוּ וְ חֹ֖...</td>\n",
       "      <td>וְ ר֣וּחַ אֱלֹהִ֔ים מְרַחֶ֖פֶת עַל ־ פְּנֵ֥י ה...</td>\n",
       "      <td>and/ the/ earth &lt;it&gt; was formlessness and/ emp...</td>\n",
       "      <td>[the] deep and/ [the] spirit of God [was] hove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gen.1.3</td>\n",
       "      <td>Gen.1.3</td>\n",
       "      <td>וַ יֹּ֥אמֶר אֱלֹהִ֖ים יְהִ֣י א֑וֹר וַֽ יְהִי ־...</td>\n",
       "      <td>and/ he said God let it be light and/ there wa...</td>\n",
       "      <td>וַ יֹּ֥אמֶר אֱלֹהִ֖ים יְהִ֣י א֑וֹר</td>\n",
       "      <td>וַֽ יְהִי ־ אֽוֹר ׃</td>\n",
       "      <td>and/ he said God let it</td>\n",
       "      <td>be light and/ there was light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gen.1.4</td>\n",
       "      <td>Gen.1.4</td>\n",
       "      <td>וַ יַּ֧רְא אֱלֹהִ֛ים אֶת ־ הָ א֖וֹר כִּי ־ ט֑ו...</td>\n",
       "      <td>and/ he saw God &lt;obj.&gt; the/ light that [it was...</td>\n",
       "      <td>וַ יַּ֧רְא אֱלֹהִ֛ים אֶת ־ הָ א֖וֹר כִּי ־ ט֑וֹב</td>\n",
       "      <td>וַ יַּבְדֵּ֣ל אֱלֹהִ֔ים בֵּ֥ין הָ א֖וֹר וּ בֵ֥...</td>\n",
       "      <td>and/ he saw God &lt;obj.&gt; the/ light that [it was...</td>\n",
       "      <td>and/ he separated God between the/ light and/ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gen.1.5</td>\n",
       "      <td>Gen.1.5</td>\n",
       "      <td>וַ יִּקְרָ֨א אֱלֹהִ֤ים ׀ לָ אוֹר֙ י֔וֹם וְ לַ ...</td>\n",
       "      <td>and/ he called God &lt;to&gt; the/ light day and/ &lt;t...</td>\n",
       "      <td>וַ יִּקְרָ֨א אֱלֹהִ֤ים ׀ לָ אוֹר֙ י֔וֹם וְ לַ ...</td>\n",
       "      <td>וַֽ יְהִי ־ עֶ֥רֶב וַֽ יְהִי ־ בֹ֖קֶר י֥וֹם אֶ...</td>\n",
       "      <td>and/ he called God &lt;to&gt; the/ light day and/ &lt;t...</td>\n",
       "      <td>he called night and/ there was evening and/ th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   eng_ref  heb_ref                                               line  \\\n",
       "0  Gen.1.1  Gen.1.1  בְּ רֵאשִׁ֖ית בָּרָ֣א אֱלֹהִ֑ים אֵ֥ת הַ שָּׁמַ...   \n",
       "1  Gen.1.2  Gen.1.2  וְ הָ אָ֗רֶץ הָיְתָ֥ה תֹ֙הוּ֙ וָ בֹ֔הוּ וְ חֹ֖...   \n",
       "2  Gen.1.3  Gen.1.3  וַ יֹּ֥אמֶר אֱלֹהִ֖ים יְהִ֣י א֑וֹר וַֽ יְהִי ־...   \n",
       "3  Gen.1.4  Gen.1.4  וַ יַּ֧רְא אֱלֹהִ֛ים אֶת ־ הָ א֖וֹר כִּי ־ ט֑ו...   \n",
       "4  Gen.1.5  Gen.1.5  וַ יִּקְרָ֨א אֱלֹהִ֤ים ׀ לָ אוֹר֙ י֔וֹם וְ לַ ...   \n",
       "\n",
       "                                         translation  \\\n",
       "0  in/ beginning he created God <obj.> the/ heave...   \n",
       "1  and/ the/ earth <it> was formlessness and/ emp...   \n",
       "2  and/ he said God let it be light and/ there wa...   \n",
       "3  and/ he saw God <obj.> the/ light that [it was...   \n",
       "4  and/ he called God <to> the/ light day and/ <t...   \n",
       "\n",
       "                                              half_a  \\\n",
       "0                    בְּ רֵאשִׁ֖ית בָּרָ֣א אֱלֹהִ֑ים   \n",
       "1  וְ הָ אָ֗רֶץ הָיְתָ֥ה תֹ֙הוּ֙ וָ בֹ֔הוּ וְ חֹ֖...   \n",
       "2                 וַ יֹּ֥אמֶר אֱלֹהִ֖ים יְהִ֣י א֑וֹר   \n",
       "3   וַ יַּ֧רְא אֱלֹהִ֛ים אֶת ־ הָ א֖וֹר כִּי ־ ט֑וֹב   \n",
       "4  וַ יִּקְרָ֨א אֱלֹהִ֤ים ׀ לָ אוֹר֙ י֔וֹם וְ לַ ...   \n",
       "\n",
       "                                              half_b  \\\n",
       "0             אֵ֥ת הַ שָּׁמַ֖יִם וְ אֵ֥ת הָ אָֽרֶץ ׃   \n",
       "1  וְ ר֣וּחַ אֱלֹהִ֔ים מְרַחֶ֖פֶת עַל ־ פְּנֵ֥י ה...   \n",
       "2                                וַֽ יְהִי ־ אֽוֹר ׃   \n",
       "3  וַ יַּבְדֵּ֣ל אֱלֹהִ֔ים בֵּ֥ין הָ א֖וֹר וּ בֵ֥...   \n",
       "4  וַֽ יְהִי ־ עֶ֥רֶב וַֽ יְהִי ־ בֹ֖קֶר י֥וֹם אֶ...   \n",
       "\n",
       "                                             trans_a  \\\n",
       "0                in/ beginning he created God <obj.>   \n",
       "1  and/ the/ earth <it> was formlessness and/ emp...   \n",
       "2                            and/ he said God let it   \n",
       "3  and/ he saw God <obj.> the/ light that [it was...   \n",
       "4  and/ he called God <to> the/ light day and/ <t...   \n",
       "\n",
       "                                             trans_b  \n",
       "0                the/ heavens and/ <obj.> the/ earth  \n",
       "1  [the] deep and/ [the] spirit of God [was] hove...  \n",
       "2                      be light and/ there was light  \n",
       "3  and/ he separated God between the/ light and/ ...  \n",
       "4  he called night and/ there was evening and/ th...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "half_a = []\n",
    "half_b = []\n",
    "for i, row in all_OT.iterrows():\n",
    "    #print(row)\n",
    "    if row['half_b'] != \"\":\n",
    "        words = row['translation'].split()\n",
    "        half_a.append(\" \".join(words[:len(words)//2]))\n",
    "        half_b.append(\" \".join(words[len(words)//2:]))\n",
    "    else:\n",
    "        half_a.append(row['translation'])\n",
    "        half_b.append(\"\")\n",
    "\n",
    "all_OT['trans_a'] = half_a\n",
    "all_OT['trans_b'] = half_b\n",
    "\n",
    "all_OT.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_OT.to_dict('records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the output as a JSON file\n",
    "with open('../data/STEP/OT_aligned_sep.json', 'w', encoding='utf-8') as out_f:\n",
    "    for line in all_data:\n",
    "        json.dump(line, out_f, ensure_ascii=False)\n",
    "        out_f.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'eng_ref': 'Gen.1.1',\n",
       "  'heb_ref': 'Gen.1.1',\n",
       "  'line': 'בְּ רֵאשִׁ֖ית בָּרָ֣א אֱלֹהִ֑ים אֵ֥ת הַ שָּׁמַ֖יִם וְ אֵ֥ת הָ אָֽרֶץ ׃',\n",
       "  'translation': 'in/ beginning he created God <obj.> the/ heavens and/ <obj.> the/ earth',\n",
       "  'half_a': 'בְּ רֵאשִׁ֖ית בָּרָ֣א אֱלֹהִ֑ים',\n",
       "  'half_b': 'אֵ֥ת הַ שָּׁמַ֖יִם וְ אֵ֥ת הָ אָֽרֶץ ׃',\n",
       "  'trans_a': 'in/ beginning he created God <obj.>',\n",
       "  'trans_b': 'the/ heavens and/ <obj.> the/ earth'},\n",
       " {'eng_ref': 'Gen.1.2',\n",
       "  'heb_ref': 'Gen.1.2',\n",
       "  'line': 'וְ הָ אָ֗רֶץ הָיְתָ֥ה תֹ֙הוּ֙ וָ בֹ֔הוּ וְ חֹ֖שֶׁךְ עַל ־ פְּנֵ֣י תְה֑וֹם וְ ר֣וּחַ אֱלֹהִ֔ים מְרַחֶ֖פֶת עַל ־ פְּנֵ֥י הַ מָּֽיִם ׃',\n",
       "  'translation': 'and/ the/ earth <it> was formlessness and/ emptiness and/ darkness [was] over [the] surface of [the] deep and/ [the] spirit of God [was] hovering over [the] surface of the/ waters',\n",
       "  'half_a': 'וְ הָ אָ֗רֶץ הָיְתָ֥ה תֹ֙הוּ֙ וָ בֹ֔הוּ וְ חֹ֖שֶׁךְ עַל ־ פְּנֵ֣י תְה֑וֹם',\n",
       "  'half_b': 'וְ ר֣וּחַ אֱלֹהִ֔ים מְרַחֶ֖פֶת עַל ־ פְּנֵ֥י הַ מָּֽיִם ׃',\n",
       "  'trans_a': 'and/ the/ earth <it> was formlessness and/ emptiness and/ darkness [was] over [the] surface of',\n",
       "  'trans_b': '[the] deep and/ [the] spirit of God [was] hovering over [the] surface of the/ waters'},\n",
       " {'eng_ref': 'Gen.1.3',\n",
       "  'heb_ref': 'Gen.1.3',\n",
       "  'line': 'וַ יֹּ֥אמֶר אֱלֹהִ֖ים יְהִ֣י א֑וֹר וַֽ יְהִי ־ אֽוֹר ׃',\n",
       "  'translation': 'and/ he said God let it be light and/ there was light',\n",
       "  'half_a': 'וַ יֹּ֥אמֶר אֱלֹהִ֖ים יְהִ֣י א֑וֹר',\n",
       "  'half_b': 'וַֽ יְהִי ־ אֽוֹר ׃',\n",
       "  'trans_a': 'and/ he said God let it',\n",
       "  'trans_b': 'be light and/ there was light'},\n",
       " {'eng_ref': 'Gen.1.4',\n",
       "  'heb_ref': 'Gen.1.4',\n",
       "  'line': 'וַ יַּ֧רְא אֱלֹהִ֛ים אֶת ־ הָ א֖וֹר כִּי ־ ט֑וֹב וַ יַּבְדֵּ֣ל אֱלֹהִ֔ים בֵּ֥ין הָ א֖וֹר וּ בֵ֥ין הַ חֹֽשֶׁךְ ׃',\n",
       "  'translation': 'and/ he saw God <obj.> the/ light that [it was] good and/ he separated God between the/ light and/ between the/ darkness',\n",
       "  'half_a': 'וַ יַּ֧רְא אֱלֹהִ֛ים אֶת ־ הָ א֖וֹר כִּי ־ ט֑וֹב',\n",
       "  'half_b': 'וַ יַּבְדֵּ֣ל אֱלֹהִ֔ים בֵּ֥ין הָ א֖וֹר וּ בֵ֥ין הַ חֹֽשֶׁךְ ׃',\n",
       "  'trans_a': 'and/ he saw God <obj.> the/ light that [it was] good',\n",
       "  'trans_b': 'and/ he separated God between the/ light and/ between the/ darkness'},\n",
       " {'eng_ref': 'Gen.1.5',\n",
       "  'heb_ref': 'Gen.1.5',\n",
       "  'line': 'וַ יִּקְרָ֨א אֱלֹהִ֤ים ׀ לָ אוֹר֙ י֔וֹם וְ לַ חֹ֖שֶׁךְ קָ֣רָא לָ֑יְלָה וַֽ יְהִי ־ עֶ֥רֶב וַֽ יְהִי ־ בֹ֖קֶר י֥וֹם אֶחָֽד ׃ פ',\n",
       "  'translation': 'and/ he called God <to> the/ light day and/ <to> the/ darkness he called night and/ there was evening and/ there was morning day one',\n",
       "  'half_a': 'וַ יִּקְרָ֨א אֱלֹהִ֤ים ׀ לָ אוֹר֙ י֔וֹם וְ לַ חֹ֖שֶׁךְ קָ֣רָא לָ֑יְלָה',\n",
       "  'half_b': 'וַֽ יְהִי ־ עֶ֥רֶב וַֽ יְהִי ־ בֹ֖קֶר י֥וֹם אֶחָֽד ׃ פ',\n",
       "  'trans_a': 'and/ he called God <to> the/ light day and/ <to> the/ darkness',\n",
       "  'trans_b': 'he called night and/ there was evening and/ there was morning day one'}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('../data/STEP/OT_aligned_sep.json', 'rt', encoding='utf-8') as ifd:\n",
    "    data = []\n",
    "    for line in ifd:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "data[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "okay what do I want to do? I want to re-run two methods of chiasm scoring, both feature-based and neural embedding space\n",
    "as well as line-level and half-line level. We want to do this with books as separate trials. Also, we should probably base our baseline\n",
    "on n continuous lines within that book for a fair trial \n",
    "* half-line level\n",
    "* line level\n",
    "* paragraph level\n",
    "#### let's start with embedding it with E5.\n",
    "First want to check that how embedding models deals with Hebrew accents. check the embedding is the same with and without diacritics\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install sentence_transformers -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hopespeirs/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/usr/local/Cellar/python@3.10/3.10.15/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.15/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/hopespeirs/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/hopespeirs/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/hopespeirs/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/hopespeirs/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.15/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.15/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.15/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/hopespeirs/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/hopespeirs/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/hopespeirs/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/hopespeirs/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/hopespeirs/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/hopespeirs/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/hopespeirs/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/hopespeirs/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/hopespeirs/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/hopespeirs/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/hopespeirs/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/hopespeirs/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/hopespeirs/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/zp/rhxvk3qs3x97flzjr43q3cx40000gn/T/ipykernel_15817/3121127374.py\", line 1, in <module>\n",
      "    from sentence_transformers import SentenceTransformer\n",
      "  File \"/Users/hopespeirs/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/sentence_transformers/__init__.py\", line 9, in <module>\n",
      "    from sentence_transformers.cross_encoder.CrossEncoder import CrossEncoder\n",
      "  File \"/Users/hopespeirs/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/sentence_transformers/cross_encoder/__init__.py\", line 3, in <module>\n",
      "    from .CrossEncoder import CrossEncoder\n",
      "  File \"/Users/hopespeirs/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py\", line 14, in <module>\n",
      "    from transformers import AutoConfig, AutoModelForSequenceClassification, AutoTokenizer, is_torch_npu_available\n",
      "  File \"/Users/hopespeirs/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1755, in __getattr__\n",
      "    value = getattr(module, name)\n",
      "  File \"/Users/hopespeirs/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1754, in __getattr__\n",
      "    module = self._get_module(self._class_to_module[name])\n",
      "  File \"/Users/hopespeirs/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1764, in _get_module\n",
      "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.15/Frameworks/Python.framework/Versions/3.10/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/Users/hopespeirs/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/transformers/models/auto/modeling_auto.py\", line 21, in <module>\n",
      "    from .auto_factory import (\n",
      "  File \"/Users/hopespeirs/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py\", line 40, in <module>\n",
      "    from ...generation import GenerationMixin\n",
      "  File \"/Users/hopespeirs/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1754, in __getattr__\n",
      "    module = self._get_module(self._class_to_module[name])\n",
      "  File \"/Users/hopespeirs/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1764, in _get_module\n",
      "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.15/Frameworks/Python.framework/Versions/3.10/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/Users/hopespeirs/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/transformers/generation/utils.py\", line 28, in <module>\n",
      "    from ..cache_utils import (\n",
      "  File \"/Users/hopespeirs/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/transformers/cache_utils.py\", line 1826, in <module>\n",
      "    class OffloadedStaticCache(StaticCache):\n",
      "  File \"/Users/hopespeirs/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/transformers/cache_utils.py\", line 1891, in OffloadedStaticCache\n",
      "    offload_device: Union[str, torch.device] = torch.device(\"cpu\"),\n",
      "/Users/hopespeirs/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/transformers/cache_utils.py:1891: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at  /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:68.)\n",
      "  offload_device: Union[str, torch.device] = torch.device(\"cpu\"),\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "initialization failed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n",
      "File \u001b[0;32m~/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/sentence_transformers/__init__.py:9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mCrossEncoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset, SentencesDataset\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mLoggingHandler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LoggingHandler\n",
      "File \u001b[0;32m~/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/sentence_transformers/cross_encoder/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mCrossEncoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[1;32m      5\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCrossEncoder\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenization_utils_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BatchEncoding\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PushToHubMixin\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentenceEvaluator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceEvaluator\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InputExample\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentenceTransformer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n",
      "File \u001b[0;32m~/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/sentence_transformers/evaluation/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mBinaryClassificationEvaluator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BinaryClassificationEvaluator\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mEmbeddingSimilarityEvaluator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EmbeddingSimilarityEvaluator\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mInformationRetrievalEvaluator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InformationRetrievalEvaluator\n",
      "File \u001b[0;32m~/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/sentence_transformers/evaluation/BinaryClassificationEvaluator.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m average_precision_score\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m paired_cosine_distances, paired_euclidean_distances, paired_manhattan_distances\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentenceEvaluator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceEvaluator\n",
      "File \u001b[0;32m~/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/sklearn/__init__.py:84\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     81\u001b[0m         __check_build,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     82\u001b[0m         _distributor_init,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     83\u001b[0m     )\n\u001b[0;32m---> 84\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[1;32m     87\u001b[0m     __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     88\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     89\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow_versions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    131\u001b[0m     ]\n",
      "File \u001b[0;32m~/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/sklearn/base.py:19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HTMLDocumentationLinkMixin, estimator_html_repr\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_metadata_requests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _MetadataRequester, _routing_enabled\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints\n",
      "File \u001b[0;32m~/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/sklearn/utils/__init__.py:11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _joblib, metadata_routing\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bunch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Bunch\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_chunking\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gen_batches, gen_even_slices\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m estimator_html_repr\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Make _safe_indexing importable from here for backward compat as this particular\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# helper is considered semi-private and typically very useful for third-party\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# libraries that want to comply with scikit-learn's estimator API. In particular,\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# _safe_indexing was included in our public API documentation despite the leading\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# `_` in its name.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/sklearn/utils/_chunking.py:8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval, validate_params\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchunk_generator\u001b[39m(gen, chunksize):\n\u001b[1;32m     12\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Chunk generator, ``gen`` into lists of length ``chunksize``. The last\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m    chunk may have a length less than ``chunksize``.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m csr_matrix, issparse\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _is_arraylike_not_scalar\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mInvalidParameterError\u001b[39;00m(\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m     18\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Custom exception to be raised when the parameter of a class/method/function\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m    does not have a valid type or value.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config \u001b[38;5;28;01mas\u001b[39;00m _get_config\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataConversionWarning, NotFittedError, PositiveSpectrumWarning\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_array_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _asarray_with_order, _is_numpy_namespace, get_namespace\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfixes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ComplexWarning, _preserve_dia_indices_dtype\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_isfinite\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FiniteStatus, cy_isfinite\n",
      "File \u001b[0;32m~/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/sklearn/utils/_array_api.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mspecial\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfixes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse_version\n\u001b[1;32m     13\u001b[0m _NUMPY_NAMESPACE_NAMES \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray_api_compat.numpy\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21myield_namespaces\u001b[39m(include_numpy_namespaces\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/sklearn/utils/fixes.py:21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/scipy/stats/__init__.py:610\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m.. _statsrefmanual:\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    605\u001b[0m \n\u001b[1;32m    606\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_warnings_errors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (ConstantInputWarning, NearConstantInputWarning,\n\u001b[1;32m    609\u001b[0m                                DegenerateDataWarning, FitError)\n\u001b[0;32m--> 610\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_stats_py\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_variation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m variation\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/scipy/stats/_stats_py.py:56\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_stats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _kendall_dis, _toint64, _weightedrankedtau\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataclasses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataclass, field\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_hypotests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _all_partitions\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_stats_pythran\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _compute_outer_prob_inside_method\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_resampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (MonteCarloMethod, PermutationMethod, BootstrapMethod,\n\u001b[1;32m     59\u001b[0m                           monte_carlo_test, permutation_test, bootstrap,\n\u001b[1;32m     60\u001b[0m                           _batch_generator)\n",
      "File \u001b[0;32m~/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/scipy/stats/_hypotests.py:13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_continuous_distns\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m norm\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gamma, kv, gammaln\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfft\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ifft\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_stats_pythran\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _a_ij_Aij_Dij2\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_stats_pythran\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     16\u001b[0m     _concordant_pairs \u001b[38;5;28;01mas\u001b[39;00m _P, _discordant_pairs \u001b[38;5;28;01mas\u001b[39;00m _Q\n\u001b[1;32m     17\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/scipy/fft/__init__.py:92\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_realtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dct, idct, dst, idst, dctn, idctn, dstn, idstn\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fftlog\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fht, ifht, fhtoffset\n\u001b[0;32m---> 92\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_helper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     93\u001b[0m     next_fast_len, prev_fast_len, fftfreq,\n\u001b[1;32m     94\u001b[0m     rfftfreq, fftshift, ifftshift)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_backend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (set_backend, skip_backend, set_global_backend,\n\u001b[1;32m     96\u001b[0m                        register_backend)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pocketfft\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhelper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m set_workers, get_workers\n",
      "File \u001b[0;32m~/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/scipy/fft/_helper.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m update_wrapper, lru_cache\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pocketfft\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m helper \u001b[38;5;28;01mas\u001b[39;00m _helper\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_array_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m array_namespace\n",
      "File \u001b[0;32m~/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/scipy/fft/_pocketfft/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\" FFT backend using pypocketfft \"\"\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbasic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrealtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhelper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/Documents/projects/intertextuality_rewrite/literary-translation/.venv/lib/python3.10/site-packages/scipy/fft/_pocketfft/basic.py:6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pypocketfft \u001b[38;5;28;01mas\u001b[39;00m pfft\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhelper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (_asfarray, _init_nd_shape_and_axes, _datacopied,\n\u001b[1;32m      8\u001b[0m                      _fix_shape, _fix_shape_1d, _normalization,\n\u001b[1;32m      9\u001b[0m                      _workers)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mc2c\u001b[39m(forward, x, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, overwrite_x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     12\u001b[0m         workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, plan\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[0;31mImportError\u001b[0m: initialization failed"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('intfloat/multilingual-e5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# okay, let's sort data into books, what structure to use? Dict. As always\n",
    "books = {}\n",
    "for line in all_data:\n",
    "    book = line['heb_ref'].split('.')[0]\n",
    "    if book not in books:\n",
    "        books[book] = [line]\n",
    "    else:\n",
    "        books[book].append(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_cantillation_marks(text):\n",
    "    # Define the regex pattern\n",
    "    # U+05C3 is a sof pasuq, we want to keep that.\n",
    "    # pattern = r'[\\u0591-\\u05AF\\u05C0-\\u05C2\\u05C4-\\u05C7\\u05F3\\u05F4]'\n",
    "    # actually remove sof pasuq\n",
    "    pattern = r'[\\u0591-\\u05AF\\u05C0-\\u05C7\\u05F3\\u05F4]'\n",
    "\n",
    "    # Use the sub() function to replace matches with an empty string\n",
    "    cleaned_text = re.sub(pattern, '', text)\n",
    "    \n",
    "    return cleaned_text\n",
    "def remove_nikkud(text):\n",
    "    # Define the regex pattern\n",
    "    return re.sub(r'[\\u0591-\\u05C7]', '', text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "בְּרֵאשִׁ֖ית בָּרָ֣א אֱלֹהִ֑ים אֵ֥ת הַשָּׁמַ֖יִם וְאֵ֥ת הָאָֽרֶץ׃\n",
      "בְּרֵאשִית בָּרָא אֱלֹהִים אֵת הַשָּמַיִם וְאֵת הָאָֽרֶץ\n",
      "בראשית ברא אלהים את השמים ואת הארץ\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8897082"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "line = all_data[0]['line']\n",
    "cleaned_line = remove_cantillation_marks(line)\n",
    "modern_cleaned_line = remove_nikkud(line)\n",
    "print(line)\n",
    "print(cleaned_line)\n",
    "print(modern_cleaned_line)\n",
    "\n",
    "enc1 = model.encode(line)\n",
    "enc2 = model.encode(modern_cleaned_line)\n",
    "\n",
    "# encoding changes based on nikkud\n",
    "import numpy as np\n",
    "np.dot(enc1, enc2) # if they were the same embedding, dot product would be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.07546929, -0.00655045, -0.06118112, -0.02635499,  0.08451455,\n",
       "         0.02568321,  0.00330316,  0.0366122 ,  0.00541422,  0.03100647],\n",
       "       dtype=float32),\n",
       " array([ 0.04332992,  0.03696194, -0.02795921, -0.04710515,  0.11382207,\n",
       "         0.04877399,  0.00981134,  0.03429966,  0.01273974,  0.01509028],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc1[:10], enc2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Gen', 'Exo', 'Lev', 'Num', 'Deu', 'Jos', 'Jdg', 'Rut', '1Sa', '2Sa', '1Ki', '2Ki', '1Ch', '2Ch', 'Ezr', 'Neh', 'Est', 'Job', 'Psa', 'Pro', 'Ecc', 'Sng', 'Isa', 'Jer', 'Lam', 'Ezk', 'Dan', 'Hos', 'Jol', 'Amo', 'Oba', 'Jon', 'Mic', 'Nam', 'Hab', 'Zep', 'Hag', 'Zec', 'Mal'])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>heb_ref</th>\n",
       "      <th>eng_ref</th>\n",
       "      <th>line</th>\n",
       "      <th>half_a</th>\n",
       "      <th>half_b</th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Psa.1.1</td>\n",
       "      <td>Psa.1.1</td>\n",
       "      <td>אשרי האיש אשר לא הלך בעצת רשעים ובדרך חטאים לא...</td>\n",
       "      <td>אַ֥שְֽׁרֵי־ הָאִ֗ישׁ אֲשֶׁ֤ר׀ לֹ֥א הָלַךְ֮ בַּ...</td>\n",
       "      <td>וּבְמוֹשַׁ֥ב לֵ֝צִ֗ים לֹ֣א יָשָֽׁב׃</td>\n",
       "      <td>how blessed! [is] the/ person who not he walks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Psa.1.2</td>\n",
       "      <td>Psa.1.2</td>\n",
       "      <td>כי אם בתורת יהוה חפצו ובתורתו יהגה יומם ולילה</td>\n",
       "      <td>כִּ֤י אִ֥ם בְּתוֹרַ֥ת יְהוָ֗ה חֶ֫פְצ֥וֹ וּֽבְת...</td>\n",
       "      <td></td>\n",
       "      <td>that except [is] in/ [the] law of Yahweh delig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Psa.1.3</td>\n",
       "      <td>Psa.1.3</td>\n",
       "      <td>והיה כעץ שתול על פלגי מים אשר פריו יתן בעתו וע...</td>\n",
       "      <td>וְֽהָיָ֗ה כְּעֵץ֮ שָׁת֪וּל עַֽל־ פַּלְגֵ֫י מָ֥...</td>\n",
       "      <td>וְכֹ֖ל אֲשֶׁר־ יַעֲשֶׂ֣ה יַצְלִֽיחַ׃</td>\n",
       "      <td>and/ he is like/ a tree planted at streams of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Psa.1.4</td>\n",
       "      <td>Psa.1.4</td>\n",
       "      <td>לא כן הרשעים כי אם כמץ אשר תדפנו רוח</td>\n",
       "      <td>לֹא־ כֵ֥ן הָרְשָׁעִ֑ים</td>\n",
       "      <td>כִּ֥י אִם־ כַּ֝מֹּ֗ץ אֲֽשֶׁר־ תִּדְּפֶ֥נּוּ רֽ...</td>\n",
       "      <td>not [are] so the/ wicked [people] that except ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Psa.1.5</td>\n",
       "      <td>Psa.1.5</td>\n",
       "      <td>על כן לא יקמו רשעים במשפט וחטאים בעדת צדיקים</td>\n",
       "      <td>עַל־ כֵּ֤ן׀ לֹא־ יָקֻ֣מוּ רְ֭שָׁעִים בַּמִּשְׁ...</td>\n",
       "      <td>וְ֝חַטָּאִ֗ים בַּעֲדַ֥ת צַדִּיקִֽים׃</td>\n",
       "      <td>there- -fore not they will stand wicked [peopl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   heb_ref  eng_ref                                               line  \\\n",
       "0  Psa.1.1  Psa.1.1  אשרי האיש אשר לא הלך בעצת רשעים ובדרך חטאים לא...   \n",
       "1  Psa.1.2  Psa.1.2      כי אם בתורת יהוה חפצו ובתורתו יהגה יומם ולילה   \n",
       "2  Psa.1.3  Psa.1.3  והיה כעץ שתול על פלגי מים אשר פריו יתן בעתו וע...   \n",
       "3  Psa.1.4  Psa.1.4               לא כן הרשעים כי אם כמץ אשר תדפנו רוח   \n",
       "4  Psa.1.5  Psa.1.5       על כן לא יקמו רשעים במשפט וחטאים בעדת צדיקים   \n",
       "\n",
       "                                              half_a  \\\n",
       "0  אַ֥שְֽׁרֵי־ הָאִ֗ישׁ אֲשֶׁ֤ר׀ לֹ֥א הָלַךְ֮ בַּ...   \n",
       "1  כִּ֤י אִ֥ם בְּתוֹרַ֥ת יְהוָ֗ה חֶ֫פְצ֥וֹ וּֽבְת...   \n",
       "2  וְֽהָיָ֗ה כְּעֵץ֮ שָׁת֪וּל עַֽל־ פַּלְגֵ֫י מָ֥...   \n",
       "3                             לֹא־ כֵ֥ן הָרְשָׁעִ֑ים   \n",
       "4  עַל־ כֵּ֤ן׀ לֹא־ יָקֻ֣מוּ רְ֭שָׁעִים בַּמִּשְׁ...   \n",
       "\n",
       "                                              half_b  \\\n",
       "0                וּבְמוֹשַׁ֥ב לֵ֝צִ֗ים לֹ֣א יָשָֽׁב׃   \n",
       "1                                                      \n",
       "2               וְכֹ֖ל אֲשֶׁר־ יַעֲשֶׂ֣ה יַצְלִֽיחַ׃   \n",
       "3  כִּ֥י אִם־ כַּ֝מֹּ֗ץ אֲֽשֶׁר־ תִּדְּפֶ֥נּוּ רֽ...   \n",
       "4               וְ֝חַטָּאִ֗ים בַּעֲדַ֥ת צַדִּיקִֽים׃   \n",
       "\n",
       "                                         translation  \n",
       "0  how blessed! [is] the/ person who not he walks...  \n",
       "1  that except [is] in/ [the] law of Yahweh delig...  \n",
       "2  and/ he is like/ a tree planted at streams of ...  \n",
       "3  not [are] so the/ wicked [people] that except ...  \n",
       "4  there- -fore not they will stand wicked [peopl...  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verses = books['Psa']\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame.from_records(verses)\n",
    "df['line'] = df['line'].apply(lambda x: remove_nikkud(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:   0%|          | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 79/79 [01:30<00:00,  1.14s/it]\n"
     ]
    }
   ],
   "source": [
    "encs = model.encode(df['line'].tolist(), show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cos_sim = cosine_similarity(encs,encs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_chiasm_score(cos_sim, i, n):\n",
    "\n",
    "    # the basic chiasm score is the sum of the reversed diagonal elements of the cosine similarity matrix\n",
    "    # then we add a penalty for high similarity scores between different levels. \n",
    "    chiasm = cos_sim[i:i+n, i:i+n]\n",
    "    # now reverse the diagonal\n",
    "    chiasm = np.fliplr(chiasm)\n",
    "    score = chiasm.trace()\n",
    "    # if it's odd, subtract the middle value -- it's a self-similarity score, always 1\n",
    "    if n % 2 == 1:\n",
    "        score -= chiasm[n//2, n//2]\n",
    "    # should normalize the score to the number of lines in the chiasm. \n",
    "    # if the chiasm is even, we divide by n, if it is odd, we divide by n-1, this is to avoid penalizing odd chiasmi\n",
    "    # this is the average of lines that should be similar\n",
    "    if n%2 == 0:\n",
    "        div = n\n",
    "    else:\n",
    "        div = n-1\n",
    "    \n",
    "    neg_score = np.sum(chiasm[0, 1:-1]) + np.sum(chiasm[-1, 1:-1])\n",
    "    # need to normalize this to n\n",
    "    score = score/div - neg_score/div\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2525    0.447967\n",
       "2526    0.250000\n",
       "2524    0.237559\n",
       "190     0.062713\n",
       "2317    0.049571\n",
       "1058    0.043664\n",
       "2277    0.043040\n",
       "1512    0.042806\n",
       "2000    0.040585\n",
       "1476    0.036888\n",
       "1334    0.036461\n",
       "1826    0.036142\n",
       "1593    0.035952\n",
       "1618    0.034992\n",
       "980     0.034703\n",
       "dtype: float64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just as a quick check, get the chiasm score and then sort by that and look at what's up\n",
    "# ugh we also want to get the corresponding english translation easily. hold on. Done\n",
    "scores = {}\n",
    "for i in range(len(encs)): \n",
    "    scores[i] = get_chiasm_score(cos_sim, i=i, n=4)\n",
    "scores = pd.Series(scores)\n",
    "scores.sort_values(ascending=False).head(15)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'heb_ref': 'Psa.150.5', 'eng_ref': 'Psa.150.5', 'line': 'הַֽלְל֥וּהוּ בְצִלְצְלֵי־ שָׁ֑מַע הַֽ֝לְל֗וּהוּ בְּֽצִלְצְלֵ֥י תְרוּעָֽה׃', 'half_a': 'הַֽלְל֥וּהוּ בְצִלְצְלֵי־ שָׁ֑מַע', 'half_b': 'הַֽ֝לְל֗וּהוּ בְּֽצִלְצְלֵ֥י תְרוּעָֽה׃', 'translation': 'praise/ him with/ cymbals of sound praise/ him with/ cymbals of shouting'}\n",
      "praise/ him with/ cymbals of sound praise/ him with/ cymbals of shouting\n",
      "\tevery <the>/ breathing thing let it praise Yahweh praise Yahweh\n",
      "\n",
      "\n",
      "{'heb_ref': 'Psa.150.6', 'eng_ref': 'Psa.150.6', 'line': 'כֹּ֣ל הַ֭נְּשָׁמָה תְּהַלֵּ֥ל יָ֗הּ הַֽלְלוּ־ יָֽהּ׃', 'half_a': 'כֹּ֣ל הַ֭נְּשָׁמָה תְּהַלֵּ֥ל יָ֗הּ הַֽלְלוּ־ יָֽהּ׃', 'half_b': '', 'translation': 'every <the>/ breathing thing let it praise Yahweh praise Yahweh'}\n",
      "every <the>/ breathing thing let it praise Yahweh praise Yahweh\n",
      "\n",
      "\n",
      "{'heb_ref': 'Psa.150.4', 'eng_ref': 'Psa.150.4', 'line': 'הַֽ֭לְלוּהוּ בְתֹ֣ף וּמָח֑וֹל הַֽ֝לְל֗וּהוּ בְּמִנִּ֥ים וְעוּגָֽב׃', 'half_a': 'הַֽ֭לְלוּהוּ בְתֹ֣ף וּמָח֑וֹל', 'half_b': 'הַֽ֝לְל֗וּהוּ בְּמִנִּ֥ים וְעוּגָֽב׃', 'translation': 'praise/ him with/ tambourine and/ dancing praise/ him with/ stringed instruments and/ flute'}\n",
      "praise/ him with/ tambourine and/ dancing praise/ him with/ stringed instruments and/ flute\n",
      "\tpraise/ him with/ cymbals of sound praise/ him with/ cymbals of shouting\n",
      "\t\tevery <the>/ breathing thing let it praise Yahweh praise Yahweh\n",
      "\n",
      "\n",
      "{'heb_ref': 'Psa.18.4', 'eng_ref': 'Psa.18.3', 'line': 'מְ֭הֻלָּל אֶקְרָ֣א יְהוָ֑ה וּמִן־ אֹ֝יְבַ֗י אִוָּשֵֽׁעַ׃', 'half_a': 'מְ֭הֻלָּל אֶקְרָ֣א יְהוָ֑ה', 'half_b': 'וּמִן־ אֹ֝יְבַ֗י אִוָּשֵֽׁעַ׃', 'translation': '[the one] to be praised I call out to Yahweh and/ from enemies/ my I am delivered'}\n",
      "[the one] to be praised I call out to Yahweh and/ from enemies/ my I am delivered\n",
      "\tthey encompassed/ me [the] cords of death and/ [the] torrents of worthlessness they overwhelmed/ me\n",
      "\t\t[the] cords of Sheol they surrounded/ me they confronted/ me [the] snares of death\n",
      "\t\t\twhen <the>/ it was distress to/ me I called out to Yahweh and/ to God/ my I cried for help he heard from/ temple/ his voice/ my\n",
      "\n",
      "\n",
      "{'heb_ref': 'Psa.135.18', 'eng_ref': 'Psa.135.18', 'line': 'כְּ֭מוֹהֶם יִהְי֣וּ עֹשֵׂיהֶ֑ם כֹּ֭ל אֲשֶׁר־ בֹּטֵ֣חַ בָּהֶֽם׃', 'half_a': 'כְּ֭מוֹהֶם יִהְי֣וּ עֹשֵׂיהֶ֑ם', 'half_b': 'כֹּ֭ל אֲשֶׁר־ בֹּטֵ֣חַ בָּהֶֽם׃', 'translation': 'like/ them they will be [those who] make/ them every [one] who [is] trusting in/ them'}\n",
      "like/ them they will be [those who] make/ them every [one] who [is] trusting in/ them\n",
      "\tO house of Israel bless <obj.> Yahweh O house of Aaron bless <obj.> Yahweh\n",
      "\t\tO house of the/ Levites bless <obj.> Yahweh O [those] fearing <of> Yahweh bless <obj.> Yahweh\n",
      "\t\t\t[be] blessed Yahweh from/ Zion [who] dwells Jerusalem praise Yahweh\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx in scores.sort_values(ascending=False).head().index:\n",
    "    print(verses[idx])\n",
    "    text = [v['translation'] for v in verses[idx:idx+4]]\n",
    "    for i, line in enumerate(text):\n",
    "        space = \"\\t\"*i\n",
    "        print(space + line)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1068/1068 [00:00<00:00, 8818.87it/s]\n",
      "100%|██████████| 1067/1067 [00:00<00:00, 9352.68it/s]\n",
      "100%|██████████| 1066/1066 [00:00<00:00, 9449.43it/s]\n",
      "100%|██████████| 1065/1065 [00:00<00:00, 9549.69it/s]\n",
      "100%|██████████| 1064/1064 [00:00<00:00, 9353.02it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "n_list = [3,4,5,6,7]\n",
    "\n",
    "np.random.seed(42)\n",
    "random_starts = np.random.randint(0, cos_sim.shape[0]-max(n_list)+1, 1000)\n",
    "\n",
    "p_values = {}\n",
    "candidate_scores = {}\n",
    "for n in n_list:\n",
    "    p_values[n] = []\n",
    "    candidate_scores[n] = []\n",
    "    scores = []\n",
    "    for i in random_starts:\n",
    "        scores.append(get_chiasm_score(cos_sim, i, n))\n",
    "\n",
    "    for i in tqdm(range(0, cos_sim.shape[0]-n+1)):\n",
    "        # get the score of that chiasmus of size n\n",
    "        candidate= get_chiasm_score(cos_sim, i, n)  \n",
    "        candidate_scores[n].append(candidate)\n",
    "\n",
    "        # calculate p-value\n",
    "        # adding 1 to the numerator and denominator to avoid division by zero (laplace smoothing)\n",
    "        p = (sum([1 for s in scores if s >= candidate]) + 1) / (len(scores)+1)\n",
    "  \n",
    "        p_values[n].append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4955044955044955, 0.36663336663336665, 0.1068931068931069]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the good news: you've found this before it's been published. It does need reworking. Let's try a feature-based approach.\n",
    "How would I do that? Just a word n-gram based approach and then look at the overlap of sets in the opposing lines?\n",
    "The good news also is that once you have feature vectors, the same process will hold. Can use similarity functions, but maybe jaccard score instead of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(analyzer=lambda x: x.split() + [\"\".join(y) for y in zip(x,x[1:])] + [\"\".join(y) for y in zip(x,x[1:],x[2:])], ngram_range=(1, 3))\n",
    "word_feats = vectorizer.fit_transform(df['line'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>אאמין</th>\n",
       "      <th>אאמין כי</th>\n",
       "      <th>אאמין כי יאזין</th>\n",
       "      <th>אאמצכם</th>\n",
       "      <th>אאמצכם במו</th>\n",
       "      <th>אאמצכם במו פי</th>\n",
       "      <th>אאריך</th>\n",
       "      <th>אאריך נפשי</th>\n",
       "      <th>אב</th>\n",
       "      <th>אב או</th>\n",
       "      <th>...</th>\n",
       "      <th>תתענג</th>\n",
       "      <th>תתענג ותשא</th>\n",
       "      <th>תתענג ותשא אל</th>\n",
       "      <th>תתפלא</th>\n",
       "      <th>תתפלא בי</th>\n",
       "      <th>תתקפהו</th>\n",
       "      <th>תתקפהו כמלך</th>\n",
       "      <th>תתקפהו כמלך עתיד</th>\n",
       "      <th>תתקפהו לנצח</th>\n",
       "      <th>תתקפהו לנצח ויהלך</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1070 rows × 16917 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      אאמין  אאמין כי  אאמין כי יאזין  אאמצכם  אאמצכם במו  אאמצכם במו פי  \\\n",
       "0         0         0               0       0           0              0   \n",
       "1         0         0               0       0           0              0   \n",
       "2         0         0               0       0           0              0   \n",
       "3         0         0               0       0           0              0   \n",
       "4         0         0               0       0           0              0   \n",
       "...     ...       ...             ...     ...         ...            ...   \n",
       "1065      0         0               0       0           0              0   \n",
       "1066      0         0               0       0           0              0   \n",
       "1067      0         0               0       0           0              0   \n",
       "1068      0         0               0       0           0              0   \n",
       "1069      0         0               0       0           0              0   \n",
       "\n",
       "      אאריך  אאריך נפשי  אב  אב או  ...  תתענג  תתענג ותשא  תתענג ותשא אל  \\\n",
       "0         0           0   0      0  ...      0           0              0   \n",
       "1         0           0   0      0  ...      0           0              0   \n",
       "2         0           0   0      0  ...      0           0              0   \n",
       "3         0           0   0      0  ...      0           0              0   \n",
       "4         0           0   0      0  ...      0           0              0   \n",
       "...     ...         ...  ..    ...  ...    ...         ...            ...   \n",
       "1065      0           0   0      0  ...      0           0              0   \n",
       "1066      0           0   0      0  ...      0           0              0   \n",
       "1067      0           0   0      0  ...      0           0              0   \n",
       "1068      0           0   0      0  ...      0           0              0   \n",
       "1069      0           0   0      0  ...      0           0              0   \n",
       "\n",
       "      תתפלא  תתפלא בי  תתקפהו  תתקפהו כמלך  תתקפהו כמלך עתיד  תתקפהו לנצח  \\\n",
       "0         0         0       0            0                 0            0   \n",
       "1         0         0       0            0                 0            0   \n",
       "2         0         0       0            0                 0            0   \n",
       "3         0         0       0            0                 0            0   \n",
       "4         0         0       0            0                 0            0   \n",
       "...     ...       ...     ...          ...               ...          ...   \n",
       "1065      0         0       0            0                 0            0   \n",
       "1066      0         0       0            0                 0            0   \n",
       "1067      0         0       0            0                 0            0   \n",
       "1068      0         0       0            0                 0            0   \n",
       "1069      0         0       0            0                 0            0   \n",
       "\n",
       "      תתקפהו לנצח ויהלך  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  \n",
       "...                 ...  \n",
       "1065                  0  \n",
       "1066                  0  \n",
       "1067                  0  \n",
       "1068                  0  \n",
       "1069                  0  \n",
       "\n",
       "[1070 rows x 16917 columns]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(word_feats.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'heb_ref': 'Job.42.15', 'eng_ref': 'Job.42.15', 'line': 'וְלֹ֨א נִמְצָ֜א נָשִׁ֥ים יָפ֛וֹת כִּבְנ֥וֹת אִיּ֖וֹב בְּכָל־ הָאָ֑רֶץ וַיִּתֵּ֨ן לָהֶ֧ם אֲבִיהֶ֛ם נַחֲלָ֖ה בְּת֥וֹךְ אֲחֵיהֶֽם׃ס', 'half_a': 'וְלֹ֨א נִמְצָ֜א נָשִׁ֥ים יָפ֛וֹת כִּבְנ֥וֹת אִיּ֖וֹב בְּכָל־ הָאָ֑רֶץ', 'half_b': 'וַיִּתֵּ֨ן לָהֶ֧ם אֲבִיהֶ֛ם נַחֲלָ֖ה בְּת֥וֹךְ אֲחֵיהֶֽם׃ס'}\n",
      "{'heb_ref': 'Job.42.17', 'eng_ref': 'Job.42.17', 'line': 'וַיָּ֣מָת אִיּ֔וֹב זָקֵ֖ן וּשְׂבַ֥ע יָמִֽים׃', 'half_a': 'וַיָּ֣מָת אִיּ֔וֹב זָקֵ֖ן וּשְׂבַ֥ע יָמִֽים׃', 'half_b': ''}\n",
      "{'heb_ref': 'Job.1.16', 'eng_ref': 'Job.1.16', 'line': 'ע֣וֹד׀ זֶ֣ה מְדַבֵּ֗ר וְזֶה֮ בָּ֣א וַיֹּאמַר֒ אֵ֣שׁ אֱלֹהִ֗ים נָֽפְלָה֙ מִן־ הַשָּׁמַ֔יִם וַתִּבְעַ֥ר בַּצֹּ֛אן וּבַנְּעָרִ֖ים וַתֹּאכְלֵ֑ם וָאִמָּ֨לְטָ֧ה רַק־ אֲנִ֛י לְבַדִּ֖י לְהַגִּ֥יד לָֽךְ׃', 'half_a': 'ע֣וֹד׀ זֶ֣ה מְדַבֵּ֗ר וְזֶה֮ בָּ֣א וַיֹּאמַר֒ אֵ֣שׁ אֱלֹהִ֗ים נָֽפְלָה֙ מִן־ הַשָּׁמַ֔יִם וַתִּבְעַ֥ר בַּצֹּ֛אן וּבַנְּעָרִ֖ים וַתֹּאכְלֵ֑ם', 'half_b': 'וָאִמָּ֨לְטָ֧ה רַק־ אֲנִ֛י לְבַדִּ֖י לְהַגִּ֥יד לָֽךְ׃'}\n",
      "{'heb_ref': 'Job.1.15', 'eng_ref': 'Job.1.15', 'line': 'וַתִּפֹּ֤ל שְׁבָא֙ וַתִּקָּחֵ֔ם וְאֶת־ הַנְּעָרִ֖ים הִכּ֣וּ לְפִי־ חָ֑רֶב וָֽאִמָּ֨לְטָ֧ה רַק־ אֲנִ֛י לְבַדִּ֖י לְהַגִּ֥יד לָֽךְ׃', 'half_a': 'וַתִּפֹּ֤ל שְׁבָא֙ וַתִּקָּחֵ֔ם וְאֶת־ הַנְּעָרִ֖ים הִכּ֣וּ לְפִי־ חָ֑רֶב', 'half_b': 'וָֽאִמָּ֨לְטָ֧ה רַק־ אֲנִ֛י לְבַדִּ֖י לְהַגִּ֥יד לָֽךְ׃'}\n",
      "{'heb_ref': 'Job.1.14', 'eng_ref': 'Job.1.14', 'line': 'וּמַלְאָ֛ךְ בָּ֥א אֶל־ אִיּ֖וֹב וַיֹּאמַ֑ר הַבָּקָר֙ הָי֣וּ חֹֽרְשׁ֔וֹת וְהָאֲתֹנ֖וֹת רֹע֥וֹת עַל־ יְדֵיהֶֽם׃', 'half_a': 'וּמַלְאָ֛ךְ בָּ֥א אֶל־ אִיּ֖וֹב וַיֹּאמַ֑ר', 'half_b': 'הַבָּקָר֙ הָי֣וּ חֹֽרְשׁ֔וֹת וְהָאֲתֹנ֖וֹת רֹע֥וֹת עַל־ יְדֵיהֶֽם׃'}\n",
      "{'heb_ref': 'Job.1.6', 'eng_ref': 'Job.1.6', 'line': 'וַיְהִ֣י הַיּ֔וֹם וַיָּבֹ֙אוּ֙ בְּנֵ֣י הָאֱלֹהִ֔ים לְהִתְיַצֵּ֖ב עַל־ יְהוָ֑ה וַיָּב֥וֹא גַֽם־ הַשָּׂטָ֖ן בְּתוֹכָֽם׃', 'half_a': 'וַיְהִ֣י הַיּ֔וֹם וַיָּבֹ֙אוּ֙ בְּנֵ֣י הָאֱלֹהִ֔ים לְהִתְיַצֵּ֖ב עַל־ יְהוָ֑ה', 'half_b': 'וַיָּב֥וֹא גַֽם־ הַשָּׂטָ֖ן בְּתוֹכָֽם׃'}\n",
      "{'heb_ref': 'Job.32.14', 'eng_ref': 'Job.32.14', 'line': 'וְלֹא־ עָרַ֣ךְ אֵלַ֣י מִלִּ֑ין וּ֝בְאִמְרֵיכֶ֗ם לֹ֣א אֲשִׁיבֶֽנּוּ׃', 'half_a': 'וְלֹא־ עָרַ֣ךְ אֵלַ֣י מִלִּ֑ין', 'half_b': 'וּ֝בְאִמְרֵיכֶ֗ם לֹ֣א אֲשִׁיבֶֽנּוּ׃'}\n",
      "{'heb_ref': 'Job.32.1', 'eng_ref': 'Job.32.1', 'line': 'וַֽיִּשְׁבְּת֡וּ שְׁלֹ֤שֶׁת הָאֲנָשִׁ֣ים הָ֭אֵלֶּה מֵעֲנ֣וֹת אֶת־ אִיּ֑וֹב כִּ֤י ה֖וּא צַדִּ֣יק בְּעֵינָֽיו׃פ', 'half_a': 'וַֽיִּשְׁבְּת֡וּ שְׁלֹ֤שֶׁת הָאֲנָשִׁ֣ים הָ֭אֵלֶּה מֵעֲנ֣וֹת אֶת־ אִיּ֑וֹב', 'half_b': 'כִּ֤י ה֖וּא צַדִּ֣יק בְּעֵינָֽיו׃פ'}\n",
      "{'heb_ref': 'Job.40.3', 'eng_ref': 'Job.40.3', 'line': 'וַיַּ֖עַן אִיּ֥וֹב אֶת־ יְהוָ֗ה וַיֹּאמַֽר׃', 'half_a': 'וַיַּ֖עַן אִיּ֥וֹב אֶת־ יְהוָ֗ה וַיֹּאמַֽר׃', 'half_b': ''}\n",
      "{'heb_ref': 'Job.2.1', 'eng_ref': 'Job.2.1', 'line': 'וַיְהִ֣י הַיּ֔וֹם וַיָּבֹ֙אוּ֙ בְּנֵ֣י הָֽאֱלֹהִ֔ים לְהִתְיַצֵּ֖ב עַל־ יְהוָ֑ה וַיָּב֤וֹא גַֽם־ הַשָּׂטָן֙ בְּתֹכָ֔ם לְהִתְיַצֵּ֖ב עַל־ יְהוָֽה׃', 'half_a': 'וַיְהִ֣י הַיּ֔וֹם וַיָּבֹ֙אוּ֙ בְּנֵ֣י הָֽאֱלֹהִ֔ים לְהִתְיַצֵּ֖ב עַל־ יְהוָ֑ה', 'half_b': 'וַיָּב֤וֹא גַֽם־ הַשָּׂטָן֙ בְּתֹכָ֔ם לְהִתְיַצֵּ֖ב עַל־ יְהוָֽה׃'}\n",
      "{'heb_ref': 'Job.42.6', 'eng_ref': 'Job.42.6', 'line': 'עַל־ כֵּ֭ן אֶמְאַ֣ס וְנִחַ֑מְתִּי עַל־ עָפָ֥ר וָאֵֽפֶר׃פ', 'half_a': 'עַל־ כֵּ֭ן אֶמְאַ֣ס וְנִחַ֑מְתִּי', 'half_b': 'עַל־ עָפָ֥ר וָאֵֽפֶר׃פ'}\n",
      "{'heb_ref': 'Job.3.5', 'eng_ref': 'Job.3.5', 'line': 'יִגְאָלֻ֡הוּ חֹ֣שֶׁךְ וְ֭צַלְמָוֶת תִּשְׁכָּן־ עָלָ֣יו עֲנָנָ֑ה יְ֝בַעֲתֻ֗הוּ כִּֽמְרִ֥ירֵי יֽוֹם׃', 'half_a': 'יִגְאָלֻ֡הוּ חֹ֣שֶׁךְ וְ֭צַלְמָוֶת תִּשְׁכָּן־ עָלָ֣יו עֲנָנָ֑ה', 'half_b': 'יְ֝בַעֲתֻ֗הוּ כִּֽמְרִ֥ירֵי יֽוֹם׃'}\n",
      "{'heb_ref': 'Job.35.5', 'eng_ref': 'Job.35.5', 'line': 'הַבֵּ֣ט שָׁמַ֣יִם וּרְאֵ֑ה וְשׁ֥וּר שְׁ֝חָקִ֗ים גָּבְה֥וּ מִמֶּֽךָּ׃', 'half_a': 'הַבֵּ֣ט שָׁמַ֣יִם וּרְאֵ֑ה', 'half_b': 'וְשׁ֥וּר שְׁ֝חָקִ֗ים גָּבְה֥וּ מִמֶּֽךָּ׃'}\n",
      "{'heb_ref': 'Job.2.3', 'eng_ref': 'Job.2.3', 'line': 'וַיֹּ֨אמֶר יְהוָ֜ה אֶל־ הַשָּׂטָ֗ן הֲשַׂ֣מְתָּ לִבְּךָ֮ אֶל־ עַבְדִּ֣י אִיּוֹב֒ כִּי֩ אֵ֨ין כָּמֹ֜הוּ בָּאָ֗רֶץ אִ֣ישׁ תָּ֧ם וְיָשָׁ֛ר יְרֵ֥א אֱלֹהִ֖ים וְסָ֣ר מֵרָ֑ע וְעֹדֶ֙נּוּ֙ מַחֲזִ֣יק בְּתֻמָּת֔וֹ וַתְּסִיתֵ֥נִי ב֖וֹ לְבַלְּע֥וֹ חִנָּֽם׃', 'half_a': 'וַיֹּ֨אמֶר יְהוָ֜ה אֶל־ הַשָּׂטָ֗ן הֲשַׂ֣מְתָּ לִבְּךָ֮ אֶל־ עַבְדִּ֣י אִיּוֹב֒ כִּי֩ אֵ֨ין כָּמֹ֜הוּ בָּאָ֗רֶץ אִ֣ישׁ תָּ֧ם וְיָשָׁ֛ר יְרֵ֥א אֱלֹהִ֖ים וְסָ֣ר מֵרָ֑ע', 'half_b': 'וְעֹדֶ֙נּוּ֙ מַחֲזִ֣יק בְּתֻמָּת֔וֹ וַתְּסִיתֵ֥נִי ב֖וֹ לְבַלְּע֥וֹ חִנָּֽם׃'}\n",
      "{'heb_ref': 'Job.10.3', 'eng_ref': 'Job.10.3', 'line': 'הֲט֤וֹב לְךָ֨׀ כִּֽי־ תַעֲשֹׁ֗ק כִּֽי־ תִ֭מְאַס יְגִ֣יעַ כַּפֶּ֑יךָ וְעַל־ עֲצַ֖ת רְשָׁעִ֣ים הוֹפָֽעְתָּ׃', 'half_a': 'הֲט֤וֹב לְךָ֨׀ כִּֽי־ תַעֲשֹׁ֗ק כִּֽי־ תִ֭מְאַס יְגִ֣יעַ כַּפֶּ֑יךָ', 'half_b': 'וְעַל־ עֲצַ֖ת רְשָׁעִ֣ים הוֹפָֽעְתָּ׃'}\n"
     ]
    }
   ],
   "source": [
    "scores = {}\n",
    "for i in range(len(encs)): \n",
    "    scores[i] = get_chiasm_score(cosine_similarity(word_feats, word_feats), i=i, n=4)\n",
    "scores = pd.Series(scores)\n",
    "scores.sort_values(ascending=False).head(15)\n",
    "for idx in scores.sort_values(ascending=False).head(15).index:\n",
    "    print(verses[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so, okay, let's think about this. \n",
    "# previously, we've thought about semantic similarity as a proxy for chiasm. That might not capture wordplay and things like that\n",
    "# which lexical and phonetic features would.\n",
    "# we want, over the course of a set of half-lines, line, paragraphs, or maybe chapters \n",
    "# I suppose a completely different way of going about it is to build a model that maximises n-gram counts\n",
    "# e.g. finding the divisions rather assuming divisions are the set lines or half-lines. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
