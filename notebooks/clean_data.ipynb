{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hebrew OT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "curl -L https://raw.githubusercontent.com/STEPBible/STEPBible-Data/master/Older%20Formats/TOTHT%20Gen-Deu%20-%20Translators%20OT%20Hebrew%20Tagged%20text%20-%20STEPBible.org%20CC%20BY.txt >> ../data/STEP/Gen_Deu.txt\n",
    "curl -L https://raw.githubusercontent.com/STEPBible/STEPBible-Data/master/Older%20Formats/TOTHT%20Jos-Est%20-%20Translators%20OT%20Hebrew%20Tagged%20text%20-%20STEPBible.org%20CC%20BY.txt >> ../data/STEP/Jos_Est.txt\n",
    "curl -L https://raw.githubusercontent.com/STEPBible/STEPBible-Data/master/Older%20Formats/TOTHT%20Job-Sng%20-%20Translators%20OT%20Hebrew%20Tagged%20text%20-%20STEPBible.org%20CC%20BY.txt >> ../data/STEP/Job_Sng.txt\n",
    "curl -L https://raw.githubusercontent.com/STEPBible/STEPBible-Data/master/Older%20Formats/TOTHT%20Isa-Mal%20-%20Translators%20OT%20Hebrew%20Tagged%20text%20-%20STEPBible.org%20CC%20BY.txt >> ../data/STEP/Isa_Mal.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = '../data/STEP/'\n",
    "paths = ['Gen_Deu.txt', 'Jos_Est.txt', 'Job_Sng.txt', 'Isa_Mal.txt']\n",
    "paths = [prefix + p for p in paths]\n",
    "import json\n",
    "ATNACH = '\\u0591'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse the input data and produce the desired output\n",
    "def get_half_lines(line):\n",
    "    words = line.split()\n",
    "    split = None\n",
    "    for i, w in enumerate(words):\n",
    "        if ATNACH in w:\n",
    "            split = i\n",
    "    if split != None:\n",
    "        return ' '.join(words[:split+1]), ' '.join(words[split+1:])\n",
    "    else:\n",
    "        return line, ''\n",
    "\n",
    "\n",
    "def parse_data_file(input_file, keep_sep=False, priority='Hebrew'):\n",
    "    parsed_data = []\n",
    "    current_ref = None\n",
    "    current_text = []\n",
    "    # Open the input file for reading\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "        # Iterate through each line in the file, skipping headers\n",
    "        for line in lines[45:]:\n",
    "            columns = line.strip().split('\\t')\n",
    "            if len(columns) < 6:\n",
    "                continue  # Skip lines that do not have enough data\n",
    "\n",
    "            heb_ref, eng_ref, pointed, accented, morphology, extended_strongs = columns\n",
    "\n",
    "            # Extract the Hebrew and English references, ignoring the word number\n",
    "            heb_verse = heb_ref.split('-')[0]\n",
    "            eng_verse = eng_ref.split('-')[0]\n",
    "\n",
    "            if not keep_sep:\n",
    "                accented = accented.replace('/', '')\n",
    "            else:\n",
    "                accented = accented.replace('/', ' ')\n",
    "\n",
    "            # # If we're still processing the same reference, keep appending words\n",
    "            # as some verses break different places, this tells us whether we want Hebrew or English verse breaks to have priority\n",
    "            if priority == \"Hebrew\":\n",
    "                comp = heb_verse\n",
    "            elif priority == \"English\":\n",
    "                comp = eng_verse\n",
    "\n",
    "            if current_ref == comp:\n",
    "                current_text.append(accented)\n",
    "            else:\n",
    "                # If we encounter a new reference, store the previous one (if it exists)\n",
    "                if current_ref is not None:\n",
    "                    line = ' '.join(current_text)\n",
    "                    half_a, half_b = get_half_lines(line)\n",
    "                    parsed_data.append({\n",
    "                        'heb_ref': current_ref,\n",
    "                        'eng_ref': current_eng_ref,\n",
    "                        'line': line,\n",
    "                        'half_a': half_a,\n",
    "                        'half_b': half_b\n",
    "                    })\n",
    "                # Start collecting data for the new reference\n",
    "                current_ref = heb_verse\n",
    "                current_eng_ref = eng_verse\n",
    "                current_text = [accented]\n",
    "\n",
    "        # Append the last collected reference\n",
    "        if current_ref:\n",
    "            line = ' '.join(current_text)\n",
    "            half_a, half_b = get_half_lines(line)\n",
    "            parsed_data.append({\n",
    "                'heb_ref': heb_verse,\n",
    "                'eng_ref': eng_verse,\n",
    "                'line': line,\n",
    "                'half_a': half_a,\n",
    "                'half_b': half_b\n",
    "            })\n",
    "    return parsed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for p in paths:\n",
    "    data.extend(parse_data_file(p, keep_sep=True, priority='Hebrew'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "curl -L https://raw.githubusercontent.com/STEPBible/STEPBible-Data/master/Translators%20Amalgamated%20OT%2BNT/TAHOT%20Gen-Deu%20-%20Translators%20Amalgamated%20Hebrew%20OT%20-%20STEPBible.org%20CC%20BY.txt > ../data/STEP/Gen_Deu_eng.txt\n",
    "curl -L https://raw.githubusercontent.com/STEPBible/STEPBible-Data/master/Translators%20Amalgamated%20OT%2BNT/TAHOT%20Jos-Est%20-%20Translators%20Amalgamated%20Hebrew%20OT%20-%20STEPBible.org%20CC%20BY.txt > ../data/STEP/Jos_Est_eng.txt\n",
    "curl -L https://raw.githubusercontent.com/STEPBible/STEPBible-Data/master/Translators%20Amalgamated%20OT%2BNT/TAHOT%20Job-Sng%20-%20Translators%20Amalgamated%20Hebrew%20OT%20-%20STEPBible.org%20CC%20BY.txt > ../data/STEP/Job_Sng_eng.txt\n",
    "curl -L https://raw.githubusercontent.com/STEPBible/STEPBible-Data/master/Translators%20Amalgamated%20OT%2BNT/TAHOT%20Isa-Mal%20-%20Translators%20Amalgamated%20Hebrew%20OT%20-%20STEPBible.org%20CC%20BY.txt > ../data/STEP/Isa_Mal_eng.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def parse_eng_data_file(file_path):\n",
    "    parsed_data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "        curr_ref = None\n",
    "        for i, line in enumerate(lines):\n",
    "            if line.startswith(\"# \"):\n",
    "                ref = line.split(\"\\t\")[0].split(\"# \")[1].strip().rstrip()\n",
    "                translation = lines[i+1].split(\"#_Translation\")[1].strip().rstrip().replace('\\t', ' ')\n",
    "                if len(ref.split()) >1:\n",
    "                    # formatted as Gen.31.55 (Heb: 32.1)\n",
    "                    eng_ref = ref.split()[0]\n",
    "                    heb_ref = eng_ref.split('.')[0] + '.'+ ref.split('Heb: ')[1].replace(')', '')\n",
    "                    #heb_ref = eng_ref.split('.')[0] + '.' + ref.split()[-1].replace('(', '').replace(\")\", '')\n",
    "                    \n",
    "                else:\n",
    "                    eng_ref = ref\n",
    "                    heb_ref = eng_ref\n",
    "                \n",
    "\n",
    "                curr_ref = eng_ref\n",
    "                parsed_data.append({'eng_ref': eng_ref,\n",
    "                                    'heb_ref': heb_ref,\n",
    "                                    'translation': translation,\n",
    "                                    })         \n",
    "            elif line.startswith(f\"#_{curr_ref}\"):\n",
    "                # if there is a subsequent line with the rest of the info\n",
    "                extra_translation  = lines[i+1].split(\"#_Translation\")[1].strip().rstrip().replace('\\t', ' ')\n",
    "                # grab the last entry in parsed_data and add in the translation\n",
    "                parsed_data[-1]['translation'] += \" \" + extra_translation  \n",
    "\n",
    "    return parsed_data\n",
    "\n",
    "eng_data = []\n",
    "prefix = '../data/STEP/'\n",
    "paths = ['Gen_Deu_eng.txt','Jos_Est_eng.txt', 'Job_Sng_eng.txt', 'Isa_Mal_eng.txt']\n",
    "for p in [prefix+pth for pth in paths]:\n",
    "    eng_data.extend(parse_eng_data_file(p))\n",
    "\n",
    "eng_data[:5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's make it into a dataframe, merge on eng_ref, and then hopefully we have a perfectly aligned dataframe\n",
    "import pandas as pd\n",
    "\n",
    "heb = pd.DataFrame.from_records(data)\n",
    "heb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng = pd.DataFrame.from_records(eng_data)\n",
    "eng.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_OT = pd.merge(heb, eng, on='eng_ref')\n",
    "# this creates heb_ref_x and heb_ref_y. we want to make certain that these are the same. If so\n",
    "all_OT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_OT[all_OT['eng_ref']==None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_OT = all_OT.rename(columns = {'heb_ref_x': 'heb_ref'})\n",
    "all_OT = all_OT.drop(columns =['heb_ref_y'])\n",
    "all_OT= all_OT[['eng_ref', 'heb_ref', 'line', 'translation', 'half_a', 'half_b']]\n",
    "all_OT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_a = []\n",
    "half_b = []\n",
    "for i, row in all_OT.iterrows():\n",
    "    #print(row)\n",
    "    if row['half_b'] != \"\":\n",
    "        words = row['translation'].split()\n",
    "        half_a.append(\" \".join(words[:len(words)//2]))\n",
    "        half_b.append(\" \".join(words[len(words)//2:]))\n",
    "    else:\n",
    "        half_a.append(row['translation'])\n",
    "        half_b.append(\"\")\n",
    "\n",
    "all_OT['trans_a'] = half_a\n",
    "all_OT['trans_b'] = half_b\n",
    "\n",
    "all_OT.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_OT.to_dict('records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the output as a JSON file\n",
    "with open('../data/STEP/OT_aligned_sep.json', 'w', encoding='utf-8') as out_f:\n",
    "    for line in all_data:\n",
    "        json.dump(line, out_f, ensure_ascii=False)\n",
    "        out_f.write('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greek OT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import json\n",
    "\n",
    "# Parse the XML file\n",
    "tree = ET.parse('../data/LXX/LXX.xml')  # replace with your file name\n",
    "root = tree.getroot()\n",
    "\n",
    "# Initialize an empty list to store the output\n",
    "output = []\n",
    "\n",
    "# Iterate over all the books\n",
    "for biblebook in root.findall('BIBLEBOOK'):\n",
    "    book_number = biblebook.get('bnumber')  # Get book number\n",
    "    \n",
    "    # Iterate over all chapters in the book\n",
    "    for chapter in biblebook.findall('CHAPTER'):\n",
    "        chapter_number = chapter.get('cnumber')  # Get chapter number\n",
    "        \n",
    "        # Iterate over all verses in the chapter\n",
    "        for verse in chapter.findall('VERS'):\n",
    "            verse_number = verse.get('vnumber')  # Get verse number\n",
    "            \n",
    "            # Concatenate all the <gr> text elements for this verse\n",
    "            verse_text = ' '.join([gr.text for gr in verse.findall('gr') if gr.text])\n",
    "\n",
    "            # Create the identifier in the format <book.chapter.verse>\n",
    "            identifier = f\"{book_number}.{chapter_number}.{verse_number}\"\n",
    "            \n",
    "            # Create a dictionary with the identifier and text\n",
    "            verse_entry = {\n",
    "                \"book_num\": book_number,\n",
    "                \"chapter\": chapter_number,\n",
    "                \"verse\": verse_number,\n",
    "                \"text\": verse_text\n",
    "            }\n",
    "            \n",
    "            # Add to the output list\n",
    "            output.append(verse_entry)\n",
    "\n",
    "# Write the output to a JSON Lines file\n",
    "with open('data/LXX.jsonl', 'w', encoding='utf-8') as f:\n",
    "    for entry in output:\n",
    "        f.write(json.dumps(entry, ensure_ascii=False) + '\\n')\n",
    "\n",
    "print(\"Finished processing the XML file.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we align it to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json('../data/LXX/LXX.json', lines=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAMES = {k:v for k,v in zip(['Genesis', 'Exodus', 'Leviticus', 'Numbers', 'Deuteronomy', 'Joshua', 'Judges', 'Ruth', '1 Samuel', '2 Samuel',\n",
    "                             '1 Kings', '2 Kings', '1 Chronicles', '2 Chronicles', 'Ezra', 'Nehemiah', 'Esther', 'Job',\n",
    "                             'Psalm', 'Proverbs', 'Ecclesiastes', 'Song of Solomon', 'Isaiah', 'Jeremiah', 'Lamentations', 'Ezekiel',\n",
    "                             'Daniel', 'Hosea', 'Joel', 'Amos', 'Obadiah', 'Jonah', 'Micah', 'Nahum', 'Habakkuk', 'Zephaniah',\n",
    "                             'Haggai', 'Zechariah', 'Malachi'],\n",
    "                            ['Gen', 'Exo', 'Lev', 'Num', 'Deu', 'Jos', 'Jdg', 'Rut', '1Sa',\n",
    "       '2Sa', '1Ki', '2Ki', '1Ch', '2Ch', 'Ezr', 'Neh', 'Est', 'Job',\n",
    "       'Psa', 'Pro', 'Ecc', 'Sng', 'Isa', 'Jer', 'Lam', 'Ezk', 'Dan',\n",
    "       'Hos', 'Jol', 'Amo', 'Oba', 'Jon', 'Mic', 'Nam', 'Hab', 'Zep',\n",
    "       'Hag', 'Zec', 'Mal'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num2name = {i+1:v for i, (k,v) in enumerate(NAMES.items())}\n",
    "num2name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['book'] = df['book_num'].apply(lambda x: num2name[x])\n",
    "\n",
    "df['eng_ref'] = df['book'] + \".\" + df['chapter'].astype(str) + \".\" + df['verse'].astype(str)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['eng_ref', 'text']].to_json('../data/LXX/LXX_aligned.json', lines=True, orient=\"records\", force_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greek NT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!curl -L https://raw.githubusercontent.com/STEPBible/STEPBible-Data/refs/heads/master/Translators%20Amalgamated%20OT%2BNT/TAGNT%20Mat-Jhn%20-%20Translators%20Amalgamated%20Greek%20NT%20-%20STEPBible.org%20CC-BY.txt >> data/Mat_Jhn.txt\n",
    "!curl -L https://raw.githubusercontent.com/STEPBible/STEPBible-Data/refs/heads/master/Translators%20Amalgamated%20OT%2BNT/TAGNT%20Act-Rev%20-%20Translators%20Amalgamated%20Greek%20NT%20-%20STEPBible.org%20CC-BY.txt >> data/Act_Rev.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_eng_data_file(file_path):\n",
    "    parsed_data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "        curr_ref = None\n",
    "        for i, line in enumerate(lines):\n",
    "            if line.startswith(\"# \"):\n",
    "                parts = line.split(\"# \")[1].split('\\t')\n",
    "                ref = parts[0]\n",
    "                if '[' in parts[1]:\n",
    "                    parts = parts[1:]\n",
    "                text = \" \".join(parts[1:]).strip().rstrip()\n",
    "                translation = lines[i+1].split(\"#_Translation\")[1].strip().rstrip().replace('\\t', ' ')\n",
    "                if len(ref.split()) >1:\n",
    "                    eng_ref = ref.split()[0]\n",
    "                    #other_ref = eng_ref.split('.')[0] + '.' + ref.split()[-1].replace('(', '').replace(\")\", '')\n",
    "                    \n",
    "                else:\n",
    "                    eng_ref = ref\n",
    "                \n",
    "                curr_ref = eng_ref\n",
    "                \n",
    "                parsed_data.append({'eng_ref': eng_ref,\n",
    "                                    'text': text,\n",
    "                                    'translation': translation,\n",
    "                                    })    \n",
    "            elif line.startswith(f\"#_{curr_ref}\"):\n",
    "                # if there is a subsequent line with the rest of the info\n",
    "                parts = line.split(\"#_\")[1].split('\\t')\n",
    "                ref = parts[0]\n",
    "                if '[' in parts[1]:\n",
    "                    parts = parts[1:]\n",
    "                extra_text = \" \".join(parts[1:]).strip().rstrip()\n",
    "                extra_translation  = lines[i+1].split(\"#_Translation\")[1].strip().rstrip().replace('\\t', ' ')\n",
    "                # grab the last entry in parsed_data and add in the translation\n",
    "                parsed_data[-1]['text'] += \" \" + extra_text\n",
    "                parsed_data[-1]['translation'] += \" \" + extra_translation  \n",
    "        \n",
    "\n",
    "    return parsed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for p in ['data/Mat_Jhn.txt', 'data/Act_Rev.txt']:\n",
    "    data.extend(parse_eng_data_file(p))\n",
    "\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[40] # checking that translations spanning multiple lines are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../data/STEP/NT_aligned.json', 'w', encoding='utf-8') as out_f:\n",
    "    for line in data:\n",
    "        json.dump(line, out_f, ensure_ascii=False)\n",
    "        out_f.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
